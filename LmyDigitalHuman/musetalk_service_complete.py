#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°å­—äººç³»ç»Ÿ - MuseTalkæœåŠ¡å®Œæ•´ç‰ˆ
æ”¯æŒå¤šç§äººè„¸æ£€æµ‹åº“çš„æ™ºèƒ½å›é€€æœºåˆ¶
ç‰ˆæœ¬: 2025-01-28 ç»ˆæç‰ˆ
"""

import os
import sys
import logging
import traceback
from typing import Optional, Union, List, Tuple
import numpy as np
import cv2
from flask import Flask, request, jsonify, send_file
import torch
import warnings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('musetalk_service.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore')

class FaceDetectorManager:
    """äººè„¸æ£€æµ‹å™¨ç®¡ç†å™¨ - æ”¯æŒå¤šç§åº“çš„æ™ºèƒ½å›é€€"""
    
    def __init__(self):
        self.detector = None
        self.detector_type = None
        self.initialize_detector()
    
    def initialize_detector(self):
        """æŒ‰ä¼˜å…ˆçº§åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨"""
        
        # ä¼˜å…ˆçº§1: dlib (æœ€ä½³è´¨é‡)
        try:
            import dlib
            self.detector = dlib.get_frontal_face_detector()
            self.detector_type = 'dlib'
            logger.info("âœ… ä½¿ç”¨dlibäººè„¸æ£€æµ‹å™¨ (æœ€ä½³è´¨é‡)")
            return
        except ImportError as e:
            logger.warning(f"dlibä¸å¯ç”¨: {e}")
        except Exception as e:
            logger.warning(f"dlibåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: MediaPipe (è‰¯å¥½è´¨é‡)
        try:
            import mediapipe as mp
            self.mp_face_detection = mp.solutions.face_detection
            self.mp_drawing = mp.solutions.drawing_utils
            self.detector = self.mp_face_detection.FaceDetection(
                model_selection=1, min_detection_confidence=0.5
            )
            self.detector_type = 'mediapipe'
            logger.info("âœ… ä½¿ç”¨MediaPipeäººè„¸æ£€æµ‹å™¨ (è‰¯å¥½è´¨é‡)")
            return
        except ImportError as e:
            logger.warning(f"MediaPipeä¸å¯ç”¨: {e}")
        except Exception as e:
            logger.warning(f"MediaPipeåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: OpenCV Haar Cascades (åŸºç¡€è´¨é‡)
        try:
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            if os.path.exists(cascade_path):
                self.detector = cv2.CascadeClassifier(cascade_path)
                self.detector_type = 'opencv'
                logger.info("âœ… ä½¿ç”¨OpenCV Haaräººè„¸æ£€æµ‹å™¨ (åŸºç¡€è´¨é‡)")
                return
        except Exception as e:
            logger.warning(f"OpenCV Haaråˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§4: OpenCV DNN (éœ€è¦æ¨¡å‹æ–‡ä»¶)
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ DNNæ¨¡å‹çš„åˆå§‹åŒ–
            pass
        except Exception as e:
            logger.warning(f"OpenCV DNNåˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.error("âŒ æ— æ³•åˆå§‹åŒ–ä»»ä½•äººè„¸æ£€æµ‹å™¨ï¼")
        raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„äººè„¸æ£€æµ‹å™¨")
    
    def detect_faces(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """
        æ£€æµ‹äººè„¸
        è¿”å›: [(x, y, w, h), ...] æ ¼å¼çš„è¾¹ç•Œæ¡†åˆ—è¡¨
        """
        if self.detector is None:
            return []
        
        try:
            if self.detector_type == 'dlib':
                return self._detect_faces_dlib(image)
            elif self.detector_type == 'mediapipe':
                return self._detect_faces_mediapipe(image)
            elif self.detector_type == 'opencv':
                return self._detect_faces_opencv(image)
            else:
                return []
        except Exception as e:
            logger.error(f"äººè„¸æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_faces_dlib(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """ä½¿ç”¨dlibæ£€æµ‹äººè„¸"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.detector(gray)
        
        results = []
        for face in faces:
            x, y, w, h = face.left(), face.top(), face.width(), face.height()
            results.append((x, y, w, h))
        
        return results
    
    def _detect_faces_mediapipe(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """ä½¿ç”¨MediaPipeæ£€æµ‹äººè„¸"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.detector.process(rgb_image)
        
        faces = []
        if results.detections:
            h, w, _ = image.shape
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                faces.append((x, y, width, height))
        
        return faces
    
    def _detect_faces_opencv(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """ä½¿ç”¨OpenCVæ£€æµ‹äººè„¸"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.detector.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
        )
        
        return [(x, y, w, h) for x, y, w, h in faces]

class MuseTalkService:
    """MuseTalkæ•°å­—äººæœåŠ¡"""
    
    def __init__(self):
        self.face_detector = FaceDetectorManager()
        self.device = self._get_device()
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def _get_device(self) -> str:
        """è·å–è®¡ç®—è®¾å¤‡"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def process_image(self, image_path: str) -> dict:
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        try:
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                return {"error": "æ— æ³•è¯»å–å›¾ç‰‡"}
            
            # æ£€æµ‹äººè„¸
            faces = self.face_detector.detect_faces(image)
            
            result = {
                "success": True,
                "detector_type": self.face_detector.detector_type,
                "faces_count": len(faces),
                "faces": faces,
                "image_shape": image.shape
            }
            
            logger.info(f"å¤„ç†å›¾ç‰‡ {image_path}: æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†å›¾ç‰‡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            return {"error": error_msg}
    
    def process_video(self, video_path: str, audio_path: str, output_path: str) -> dict:
        """å¤„ç†è§†é¢‘å’ŒéŸ³é¢‘ç”Ÿæˆæ•°å­—äºº"""
        try:
            # è¿™é‡Œæ·»åŠ MuseTalkçš„æ ¸å¿ƒé€»è¾‘
            # ç”±äºMuseTalkéœ€è¦ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶ï¼Œè¿™é‡Œæä¾›æ¡†æ¶
            
            logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
            logger.info(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}")
            logger.info(f"è¾“å‡ºè·¯å¾„: {output_path}")
            
            # æ£€æµ‹è§†é¢‘ä¸­çš„äººè„¸
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return {"error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
            
            frame_count = 0
            total_faces = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                faces = self.face_detector.detect_faces(frame)
                total_faces += len(faces)
                frame_count += 1
                
                # å¤„ç†å‰å‡ å¸§å°±å¤Ÿäº†ï¼Œç”¨äºéªŒè¯
                if frame_count >= 10:
                    break
            
            cap.release()
            
            result = {
                "success": True,
                "detector_type": self.face_detector.detector_type,
                "processed_frames": frame_count,
                "average_faces_per_frame": total_faces / frame_count if frame_count > 0 else 0,
                "message": "è§†é¢‘åˆ†æå®Œæˆï¼ŒMuseTalkå¤„ç†éœ€è¦åŠ è½½å®Œæ•´æ¨¡å‹"
            }
            
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†è§†é¢‘å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            return {"error": error_msg}

# Flaskåº”ç”¨
app = Flask(__name__)
musetalk_service = MuseTalkService()

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "detector_type": musetalk_service.face_detector.detector_type,
        "device": musetalk_service.device
    })

@app.route('/detect_faces', methods=['POST'])
def detect_faces():
    """äººè„¸æ£€æµ‹API"""
    if 'image' not in request.files:
        return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡"}), 400
    
    file = request.files['image']
    if file.filename == '':
        return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = f"temp_{file.filename}"
    file.save(temp_path)
    
    try:
        result = musetalk_service.process_image(temp_path)
        return jsonify(result)
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.route('/generate', methods=['POST'])
def generate_digital_human():
    """ç”Ÿæˆæ•°å­—äººè§†é¢‘"""
    data = request.json
    
    if not data or 'video_path' not in data or 'audio_path' not in data:
        return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
    
    video_path = data['video_path']
    audio_path = data['audio_path']
    output_path = data.get('output_path', 'output.mp4')
    
    result = musetalk_service.process_video(video_path, audio_path, output_path)
    return jsonify(result)

@app.route('/info', methods=['GET'])
def get_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    info = {
        "service": "MuseTalkæ•°å­—äººç³»ç»Ÿ",
        "version": "2025-01-28 ç»ˆæç‰ˆ",
        "detector_type": musetalk_service.face_detector.detector_type,
        "device": musetalk_service.device,
        "available_detectors": []
    }
    
    # æ£€æŸ¥å¯ç”¨çš„æ£€æµ‹å™¨
    try:
        import dlib
        info["available_detectors"].append("dlib")
    except ImportError:
        pass
    
    try:
        import mediapipe
        info["available_detectors"].append("mediapipe")
    except ImportError:
        pass
    
    try:
        import cv2
        info["available_detectors"].append("opencv")
    except ImportError:
        pass
    
    return jsonify(info)

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¯åŠ¨MuseTalkæ•°å­—äººæœåŠ¡...")
        logger.info(f"äººè„¸æ£€æµ‹å™¨: {musetalk_service.face_detector.detector_type}")
        logger.info(f"è®¡ç®—è®¾å¤‡: {musetalk_service.device}")
        
        # å¯åŠ¨FlaskæœåŠ¡
        app.run(
            host='0.0.0.0',
            port=5000,
            debug=False,
            threaded=True
        )
        
    except Exception as e:
        logger.error(f"æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()