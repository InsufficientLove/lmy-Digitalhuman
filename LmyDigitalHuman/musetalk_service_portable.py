#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¾¿æºå¼MuseTalk HTTPæœåŠ¡
æ”¯æŒåŠ¨æ€GPUé…ç½®å’Œå¤šæœºå™¨éƒ¨ç½²
å°†æ­¤æ–‡ä»¶å¤åˆ¶åˆ° F:\AI\DigitalHuman_Portable\MuseTalk\musetalk_service.py
"""

import os
import sys
import json
import logging
import time
from pathlib import Path
from flask import Flask, request, jsonify
from flask_cors import CORS

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = Path(__file__).parent.absolute()
BASE_DIR = SCRIPT_DIR.parent
CONFIG_DIR = BASE_DIR / "config"
LOGS_DIR = BASE_DIR / "logs"

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
LOGS_DIR.mkdir(exist_ok=True)

# åŠ è½½GPUé…ç½®
def load_gpu_config():
    """åŠ è½½GPUé…ç½®"""
    gpu_config_file = CONFIG_DIR / "gpu_config.env"
    if gpu_config_file.exists():
        with open(gpu_config_file, 'r') as f:
            for line in f:
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value
                    print(f"âœ… åŠ è½½ç¯å¢ƒå˜é‡: {key}={value}")

# åŠ è½½æœåŠ¡é…ç½®
def load_service_config():
    """åŠ è½½æœåŠ¡é…ç½®"""
    config_file = CONFIG_DIR / "service_config.json"
    default_config = {
        "host": "0.0.0.0",
        "port": 8000,
        "debug": False,
        "model_config": {
            "batch_size": 4,
            "fps": 25,
            "quality": "medium",
            "enable_emotion": True
        }
    }
    
    if config_file.exists():
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                print(f"âœ… åŠ è½½æœåŠ¡é…ç½®: {config_file}")
                return {**default_config, **config}
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
    
    return default_config

# æ—©æœŸåŠ è½½é…ç½®
load_gpu_config()
service_config = load_service_config()

# æ·»åŠ MuseTalkè·¯å¾„
sys.path.append(str(SCRIPT_DIR))

app = Flask(__name__)
CORS(app)

# é…ç½®æ—¥å¿—
log_file = LOGS_DIR / "musetalk_service.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
musetalk_model = None
gpu_info = {}

def detect_gpu_info():
    """æ£€æµ‹GPUä¿¡æ¯"""
    global gpu_info
    try:
        import torch
        gpu_info = {
            "torch_version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            "current_device": torch.cuda.current_device() if torch.cuda.is_available() else None,
            "gpu_names": []
        }
        
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_info["gpu_names"].append(f"GPU {i}: {gpu_name}")
                
        logger.info(f"GPUä¿¡æ¯: {gpu_info}")
        
        # è®¾ç½®GPUè®¾å¤‡
        cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '0')
        if torch.cuda.is_available():
            logger.info(f"ä½¿ç”¨GPUè®¾å¤‡: {cuda_devices}")
        else:
            logger.warning("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            
    except Exception as e:
        logger.error(f"GPUæ£€æµ‹å¤±è´¥: {e}")
        gpu_info = {"error": str(e)}

def initialize_musetalk():
    """åˆå§‹åŒ–MuseTalkæ¨¡å‹"""
    global musetalk_model
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–MuseTalkæ¨¡å‹...")
        
        # æ£€æµ‹GPU
        detect_gpu_info()
        
        # TODO: è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„MuseTalk APIè¿›è¡Œå®ç°
        # ç¤ºä¾‹ä»£ç ç»“æ„:
        """
        from musetalk.models import MuseTalkModel
        from musetalk.utils.preprocess import AudioProcessor, ImageProcessor
        
        # åˆå§‹åŒ–æ¨¡å‹
        musetalk_model = {
            'model': MuseTalkModel.from_pretrained(model_path),
            'audio_processor': AudioProcessor(),
            'image_processor': ImageProcessor(),
            'config': service_config['model_config']
        }
        """
        
        # ä¸´æ—¶æ¨¡æ‹Ÿåˆå§‹åŒ–
        musetalk_model = {
            'initialized': True,
            'config': service_config['model_config'],
            'gpu_info': gpu_info
        }
        
        logger.info("MuseTalkæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"MuseTalkæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        "status": "healthy",
        "service": "MuseTalk Portable",
        "model_loaded": musetalk_model is not None,
        "gpu_info": gpu_info,
        "environment": {
            "cuda_visible_devices": os.environ.get('CUDA_VISIBLE_DEVICES', 'N/A'),
            "base_dir": str(BASE_DIR),
            "script_dir": str(SCRIPT_DIR),
            "python_version": sys.version
        },
        "config": service_config
    })

@app.route('/generate', methods=['POST'])
def generate_video():
    """ç”Ÿæˆæ•°å­—äººè§†é¢‘æ¥å£"""
    try:
        if musetalk_model is None:
            return jsonify({
                "success": False,
                "message": "MuseTalkæ¨¡å‹æœªåˆå§‹åŒ–"
            }), 500
            
        data = request.json
        logger.info(f"æ”¶åˆ°ç”Ÿæˆè¯·æ±‚: {data}")
        
        # æå–å‚æ•°
        avatar_image = data.get('avatar_image')
        audio_path = data.get('audio_path')
        result_dir = data.get('result_dir')
        output_filename = data.get('output_filename', f'musetalk_{int(time.time())}.mp4')
        
        # ä½¿ç”¨æœåŠ¡é…ç½®çš„é»˜è®¤å€¼
        model_config = service_config['model_config']
        fps = data.get('fps', model_config['fps'])
        batch_size = data.get('batch_size', model_config['batch_size'])
        quality = data.get('quality', model_config['quality'])
        enable_emotion = data.get('enable_emotion', model_config['enable_emotion'])
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(avatar_image):
            return jsonify({
                "success": False,
                "message": f"å¤´åƒå›¾ç‰‡ä¸å­˜åœ¨: {avatar_image}"
            }), 400
            
        if not os.path.exists(audio_path):
            return jsonify({
                "success": False,
                "message": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
            }), 400
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(result_dir, exist_ok=True)
        output_path = os.path.join(result_dir, output_filename)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        logger.info(f"å¼€å§‹ç”Ÿæˆè§†é¢‘:")
        logger.info(f"  å¤´åƒ: {avatar_image}")
        logger.info(f"  éŸ³é¢‘: {audio_path}")
        logger.info(f"  è¾“å‡º: {output_path}")
        logger.info(f"  å‚æ•°: fps={fps}, batch_size={batch_size}, quality={quality}")
        
        # TODO: è°ƒç”¨å®é™…çš„MuseTalkç”Ÿæˆé€»è¾‘
        """
        # å®é™…å®ç°ç¤ºä¾‹:
        result = musetalk_model['model'].generate(
            avatar_image=avatar_image,
            audio_path=audio_path,
            output_path=output_path,
            fps=fps,
            batch_size=batch_size,
            quality=quality,
            enable_emotion=enable_emotion,
            device=f"cuda:{os.environ.get('CUDA_VISIBLE_DEVICES', '0').split(',')[0]}" if gpu_info.get('cuda_available') else "cpu"
        )
        """
        
        # ä¸´æ—¶æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹
        logger.info("æ­£åœ¨ç”Ÿæˆæ•°å­—äººè§†é¢‘...")
        
        # æ ¹æ®GPUæ•°é‡è°ƒæ•´å¤„ç†æ—¶é—´æ¨¡æ‹Ÿ
        gpu_count = gpu_info.get('gpu_count', 1)
        base_time = 3.0  # åŸºç¡€å¤„ç†æ—¶é—´
        processing_time_sim = base_time / max(1, gpu_count)  # GPUå¹¶è¡ŒåŠ é€Ÿ
        
        time.sleep(processing_time_sim)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        with open(output_path, 'w') as f:
            f.write(f"# MuseTalkç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶\n# å‚æ•°: fps={fps}, quality={quality}\n# GPU: {gpu_info}")
        
        processing_time = (time.time() - start_time) * 1000
        file_size = os.path.getsize(output_path)
        
        logger.info(f"è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path}")
        logger.info(f"å¤„ç†æ—¶é—´: {processing_time:.0f}ms")
        logger.info(f"æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        return jsonify({
            "success": True,
            "video_path": output_path,
            "message": "è§†é¢‘ç”ŸæˆæˆåŠŸ",
            "duration": 10.0,
            "processing_time": int(processing_time),
            "file_size": file_size,
            "metadata": {
                "fps": fps,
                "quality": quality,
                "resolution": "1280x720" if quality == "medium" else "1920x1080",
                "gpu_used": gpu_info.get('gpu_names', ['CPU']),
                "batch_size": batch_size
            }
        })
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆè§†é¢‘å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({
            "success": False,
            "message": f"ç”Ÿæˆå¤±è´¥: {str(e)}"
        }), 500

@app.route('/config', methods=['GET'])
def get_config():
    """è·å–å½“å‰é…ç½®"""
    return jsonify({
        "service_config": service_config,
        "gpu_config": {
            "cuda_visible_devices": os.environ.get('CUDA_VISIBLE_DEVICES'),
            "pytorch_cuda_alloc_conf": os.environ.get('PYTORCH_CUDA_ALLOC_CONF')
        },
        "paths": {
            "base_dir": str(BASE_DIR),
            "script_dir": str(SCRIPT_DIR),
            "config_dir": str(CONFIG_DIR),
            "logs_dir": str(LOGS_DIR)
        }
    })

@app.route('/config', methods=['POST'])
def update_config():
    """æ›´æ–°é…ç½®"""
    try:
        new_config = request.json
        
        # æ›´æ–°æœåŠ¡é…ç½®
        config_file = CONFIG_DIR / "service_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(new_config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"é…ç½®å·²æ›´æ–°: {new_config}")
        
        return jsonify({
            "success": True,
            "message": "é…ç½®æ›´æ–°æˆåŠŸï¼Œé‡å¯æœåŠ¡åç”Ÿæ•ˆ"
        })
        
    except Exception as e:
        logger.error(f"é…ç½®æ›´æ–°å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "message": str(e)
        }), 500

if __name__ == '__main__':
    logger.info("="*50)
    logger.info("ğŸš€ å¯åŠ¨ä¾¿æºå¼MuseTalkæœåŠ¡")
    logger.info("="*50)
    logger.info(f"ğŸ“ åŸºç¡€ç›®å½•: {BASE_DIR}")
    logger.info(f"ğŸ“ è„šæœ¬ç›®å½•: {SCRIPT_DIR}")
    logger.info(f"ğŸ“ é…ç½®ç›®å½•: {CONFIG_DIR}")
    logger.info(f"ğŸ“ æ—¥å¿—ç›®å½•: {LOGS_DIR}")
    logger.info(f"ğŸ”§ æœåŠ¡é…ç½®: {service_config}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    if initialize_musetalk():
        host = service_config['host']
        port = service_config['port']
        debug = service_config['debug']
        
        logger.info(f"âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ")
        logger.info(f"ğŸŒ ç›‘å¬åœ°å€: http://{host}:{port}")
        logger.info(f"ğŸ¥ å¥åº·æ£€æŸ¥: http://{host}:{port}/health")
        logger.info(f"âš™ï¸ é…ç½®æ¥å£: http://{host}:{port}/config")
        
        app.run(host=host, port=port, debug=debug, threaded=True)
    else:
        logger.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼ŒæœåŠ¡æ— æ³•å¯åŠ¨")
        sys.exit(1)