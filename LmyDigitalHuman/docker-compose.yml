version: '3.8'

services:
  lmy-digital-human:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: lmy-digital-human
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ASPNETCORE_ENVIRONMENT=Production
      - ASPNETCORE_URLS=http://+:5000;https://+:5001
    ports:
      - "5000:5000"
      - "5001:5001"
    volumes:
      - ./wwwroot/videos:/app/wwwroot/videos
      - ./wwwroot/templates:/app/wwwroot/templates
      - ./temp:/app/temp
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 开发环境 - 支持远程调试
  lmy-digital-human-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: lmy-digital-human-dev
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:5000;https://+:5001
    ports:
      - "5000:5000"
      - "5001:5001"
      - "4024:4024"  # 远程调试端口
      - "2222:22"    # SSH 端口
    volumes:
      - .:/app
      - ~/.nuget/packages:/root/.nuget/packages:ro
      - ~/vsdbg:/vsdbg:ro
    stdin_open: true
    tty: true
    command: /bin/bash -c "dotnet watch run --urls http://0.0.0.0:5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Ollama 服务（如果需要本地LLM）
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ollama_data: