#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import torch
from pathlib import Path

class MuseTalkPathFixer:
    def __init__(self):
        self.script_dir = Path(__file__).parent
        print(f"å½“å‰è„šæœ¬ç›®å½•: {self.script_dir}")
        
    def diagnose_path_issue(self):
        """è¯Šæ–­MuseTalkè·¯å¾„é—®é¢˜"""
        print("=== MuseTalk è·¯å¾„è¯Šæ–­ ===")
        
        # æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•
        current_dir = os.getcwd()
        print(f"å½“å‰å·¥ä½œç›®å½•: {current_dir}")
        
        # æ£€æŸ¥é¢„æœŸçš„MuseTalkè·¯å¾„
        expected_musetalk_path = os.path.join(self.script_dir, '..', 'MuseTalk')
        expected_musetalk_path = os.path.abspath(expected_musetalk_path)
        print(f"é¢„æœŸMuseTalkè·¯å¾„: {expected_musetalk_path}")
        
        if os.path.exists(expected_musetalk_path):
            print("âœ… MuseTalkç›®å½•å­˜åœ¨")
        else:
            print("âŒ MuseTalkç›®å½•ä¸å­˜åœ¨äºé¢„æœŸä½ç½®")
            
            # æœç´¢å¯èƒ½çš„MuseTalkä½ç½®
            possible_paths = [
                os.path.join(self.script_dir, 'MuseTalk'),  # åŒçº§ç›®å½•
                os.path.join(self.script_dir, '..', '..', 'MuseTalk'),  # ä¸Šä¸Šçº§ç›®å½•
                '/workspace/MuseTalk',  # ç»å¯¹è·¯å¾„
            ]
            
            for path in possible_paths:
                abs_path = os.path.abspath(path)
                if os.path.exists(abs_path):
                    print(f"âœ… æ‰¾åˆ°MuseTalkç›®å½•: {abs_path}")
                    return abs_path
                else:
                    print(f"âŒ ä¸å­˜åœ¨: {abs_path}")
        
        return expected_musetalk_path if os.path.exists(expected_musetalk_path) else None
    
    def check_model_files(self, musetalk_path):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
        print(f"\n=== æ¨¡å‹æ–‡ä»¶æ£€æŸ¥ (è·¯å¾„: {musetalk_path}) ===")
        
        if not musetalk_path or not os.path.exists(musetalk_path):
            print("âŒ MuseTalkè·¯å¾„æ— æ•ˆ")
            return False
            
        models_path = os.path.join(musetalk_path, 'models')
        if not os.path.exists(models_path):
            print(f"âŒ modelsç›®å½•ä¸å­˜åœ¨: {models_path}")
            return False
        
        print(f"âœ… modelsç›®å½•å­˜åœ¨: {models_path}")
        
        # æ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶
        required_files = {
            "UNetæ¨¡å‹": "models/musetalkV15/unet.pth",
            "VAEé…ç½®": "models/sd-vae/config.json", 
            "VAEæ¨¡å‹(.bin)": "models/sd-vae/diffusion_pytorch_model.bin",
            "VAEæ¨¡å‹(.safetensors)": "models/sd-vae/diffusion_pytorch_model.safetensors",
            "DWPoseæ¨¡å‹": "models/dwpose/dw-ll_ucoco_384.pth"
        }
        
        all_good = True
        for name, rel_path in required_files.items():
            full_path = os.path.join(musetalk_path, rel_path)
            if os.path.exists(full_path):
                size_mb = os.path.getsize(full_path) / (1024*1024)
                print(f"âœ… {name}: {size_mb:.1f}MB")
            else:
                print(f"âŒ {name}: ä¸å­˜åœ¨ ({full_path})")
                all_good = False
        
        return all_good
    
    def test_model_import(self, musetalk_path):
        """æµ‹è¯•æ¨¡å‹å¯¼å…¥"""
        print(f"\n=== æ¨¡å‹å¯¼å…¥æµ‹è¯• ===")
        
        if not musetalk_path:
            print("âŒ MuseTalkè·¯å¾„æ— æ•ˆï¼Œè·³è¿‡å¯¼å…¥æµ‹è¯•")
            return False
        
        # æ·»åŠ MuseTalkè·¯å¾„åˆ°Pythonè·¯å¾„
        if musetalk_path not in sys.path:
            sys.path.insert(0, musetalk_path)
            print(f"âœ… æ·»åŠ è·¯å¾„åˆ°sys.path: {musetalk_path}")
        
        # å°è¯•å¯¼å…¥MuseTalkæ¨¡å—
        try:
            print("æµ‹è¯•å¯¼å…¥ musetalk.utils.utils...")
            from musetalk.utils.utils import load_all_model
            print("âœ… æˆåŠŸå¯¼å…¥ load_all_model")
            
            # åˆ‡æ¢åˆ°MuseTalkç›®å½•ï¼ˆè¿™å¾ˆé‡è¦ï¼ï¼‰
            original_cwd = os.getcwd()
            os.chdir(musetalk_path)
            print(f"âœ… åˆ‡æ¢å·¥ä½œç›®å½•åˆ°: {musetalk_path}")
            
            try:
                print("æµ‹è¯•åŠ è½½æ¨¡å‹...")
                # æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆä»…åœ¨CPUä¸Šï¼Œé¿å…GPUå†²çªï¼‰
                vae, unet, pe = load_all_model(vae_type="sd-vae")
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
                
                # æµ‹è¯•meta tensoré—®é¢˜
                if hasattr(unet.model, 'state_dict'):
                    state_dict = unet.model.state_dict()
                    meta_tensors = []
                    for name, param in state_dict.items():
                        if hasattr(param, 'is_meta') and param.is_meta:
                            meta_tensors.append(name)
                    
                    if meta_tensors:
                        print(f"âŒ å‘ç°meta tensor: {len(meta_tensors)}ä¸ª")
                        print(f"ç¤ºä¾‹: {meta_tensors[:3]}")
                        return "meta_tensor_issue"
                    else:
                        print("âœ… æ²¡æœ‰å‘ç°meta tensoré—®é¢˜")
                        return True
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                if "Cannot copy out of meta tensor" in str(e):
                    return "meta_tensor_issue"
                elif "No such file or directory" in str(e):
                    return "file_missing"
                else:
                    return f"other_error: {e}"
            finally:
                # æ¢å¤åŸå·¥ä½œç›®å½•
                os.chdir(original_cwd)
                
        except ImportError as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            return "import_error"
        
        return False
    
    def fix_meta_tensor_issue(self, musetalk_path):
        """ä¿®å¤meta tensoré—®é¢˜"""
        print(f"\n=== ä¿®å¤Meta Tensoré—®é¢˜ ===")
        
        unet_path = os.path.join(musetalk_path, "models", "musetalkV15", "unet.pth")
        if not os.path.exists(unet_path):
            print(f"âŒ UNetæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {unet_path}")
            return False
        
        try:
            print("æ­£åœ¨æ£€æŸ¥UNetæ¨¡å‹...")
            
            # åˆ‡æ¢åˆ°MuseTalkç›®å½•
            original_cwd = os.getcwd()
            os.chdir(musetalk_path)
            
            # åŠ è½½æ¨¡å‹æ•°æ®
            model_data = torch.load(unet_path, map_location='cpu')
            print(f"âœ… UNetæ¨¡å‹æ–‡ä»¶è¯»å–æˆåŠŸ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰meta tensor
            meta_tensor_count = 0
            if isinstance(model_data, dict):
                for key, value in model_data.items():
                    if torch.is_tensor(value) and hasattr(value, 'is_meta') and value.is_meta:
                        meta_tensor_count += 1
            
            if meta_tensor_count > 0:
                print(f"âŒ å‘ç° {meta_tensor_count} ä¸ªmeta tensor")
                print("æ­£åœ¨ä¿®å¤...")
                
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = unet_path + ".backup"
                if not os.path.exists(backup_path):
                    import shutil
                    shutil.copy2(unet_path, backup_path)
                    print(f"âœ… åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_path}")
                
                # ä¿®å¤meta tensorï¼ˆé€šè¿‡é‡æ–°ä¿å­˜å®ç°ï¼‰
                try:
                    # å¯¼å…¥UNetç±»
                    sys.path.insert(0, musetalk_path)
                    from musetalk.models.unet import UNet
                    
                    # é‡æ–°åŠ è½½æ¨¡å‹
                    config_path = os.path.join(musetalk_path, "models", "musetalkV15", "musetalk.json")
                    unet = UNet(unet_config=config_path, model_path=unet_path, device='cpu')
                    
                    # ä¿å­˜ä¿®å¤åçš„æ¨¡å‹
                    torch.save(unet.model.state_dict(), unet_path)
                    print("âœ… Meta tensoré—®é¢˜å·²ä¿®å¤")
                    
                    # éªŒè¯ä¿®å¤ç»“æœ
                    model_data_fixed = torch.load(unet_path, map_location='cpu')
                    meta_count_after = 0
                    for key, value in model_data_fixed.items():
                        if torch.is_tensor(value) and hasattr(value, 'is_meta') and value.is_meta:
                            meta_count_after += 1
                    
                    if meta_count_after == 0:
                        print("âœ… ä¿®å¤éªŒè¯æˆåŠŸï¼Œæ²¡æœ‰meta tensor")
                        return True
                    else:
                        print(f"âŒ ä¿®å¤åä»æœ‰ {meta_count_after} ä¸ªmeta tensor")
                        return False
                        
                except Exception as fix_error:
                    print(f"âŒ ä¿®å¤å¤±è´¥: {fix_error}")
                    # æ¢å¤å¤‡ä»½
                    if os.path.exists(backup_path):
                        import shutil
                        shutil.copy2(backup_path, unet_path)
                        print("å·²æ¢å¤åŸæ–‡ä»¶")
                    return False
            else:
                print("âœ… æ²¡æœ‰å‘ç°meta tensoré—®é¢˜")
                return True
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
            return False
        finally:
            os.chdir(original_cwd)
    
    def generate_path_fix_suggestions(self):
        """ç”Ÿæˆè·¯å¾„ä¿®å¤å»ºè®®"""
        print(f"\n=== è·¯å¾„ä¿®å¤å»ºè®® ===")
        
        print("åŸºäºåˆ†æï¼Œå»ºè®®æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š")
        print()
        print("1. **å·¥ä½œç›®å½•è®¾ç½®**")
        print("   ç¡®ä¿Pythonè„šæœ¬åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•ä¸­è¿è¡Œ")
        print("   åº”è¯¥åœ¨åŒ…å«MuseTalkæ–‡ä»¶å¤¹çš„ç›®å½•ä¸­è¿è¡Œ")
        print()
        print("2. **MuseTalkç›®å½•ä½ç½®**")
        print("   ç¡®è®¤MuseTalkç›®å½•ä¸MuseTalkEngineç›®å½•åœ¨åŒä¸€çº§åˆ«")
        print("   æ­£ç¡®çš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š")
        print("   ```")
        print("   digitalhuman/lmy-Digitalhuman/")
        print("   â”œâ”€â”€ MuseTalk/")
        print("   â”‚   â””â”€â”€ models/")
        print("   â””â”€â”€ MuseTalkEngine/")
        print("   ```")
        print()
        print("3. **Pythonè·¯å¾„**")
        print("   æ£€æŸ¥sys.pathæ˜¯å¦æ­£ç¡®åŒ…å«äº†MuseTalkç›®å½•")
        print()
        print("4. **æ¨¡å‹æ–‡ä»¶æƒé™**")
        print("   ç¡®ä¿Pythonè¿›ç¨‹æœ‰è¯»å–æ¨¡å‹æ–‡ä»¶çš„æƒé™")
        print()
        print("5. **GPUå†…å­˜**")
        print("   å¦‚æœæ˜¯GPUå†…å­˜ä¸è¶³ï¼Œè€ƒè™‘å‡å°‘å¹¶è¡ŒGPUæ•°é‡")

def main():
    print("MuseTalk è·¯å¾„å’Œæ¨¡å‹åŠ è½½é—®é¢˜ä¿®å¤å·¥å…·")
    print("="*50)
    
    fixer = MuseTalkPathFixer()
    
    # è¯Šæ–­è·¯å¾„é—®é¢˜
    musetalk_path = fixer.diagnose_path_issue()
    
    if musetalk_path:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        models_ok = fixer.check_model_files(musetalk_path)
        
        if models_ok:
            # æµ‹è¯•æ¨¡å‹å¯¼å…¥
            import_result = fixer.test_model_import(musetalk_path)
            
            if import_result == "meta_tensor_issue":
                print("\næ£€æµ‹åˆ°meta tensoré—®é¢˜ï¼Œå°è¯•ä¿®å¤...")
                if fixer.fix_meta_tensor_issue(musetalk_path):
                    print("âœ… Meta tensoré—®é¢˜ä¿®å¤æˆåŠŸï¼")
                    print("ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨MuseTalkæœåŠ¡")
                else:
                    print("âŒ Meta tensoré—®é¢˜ä¿®å¤å¤±è´¥")
            elif import_result == True:
                print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼MuseTalkåº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œ")
            else:
                print(f"\nâŒ å‘ç°é—®é¢˜: {import_result}")
        else:
            print("\nâŒ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å¤±è´¥")
    else:
        print("\nâŒ æ— æ³•æ‰¾åˆ°MuseTalkç›®å½•")
    
    # ç”Ÿæˆä¿®å¤å»ºè®®
    fixer.generate_path_fix_suggestions()

if __name__ == "__main__":
    main()