version: "3.9"

services:
  musetalk-python:
    volumes:
      # 将宿主机模型目录直接映射为代码期望的 ./models（/opt/musetalk/repo/MuseTalk/models）
      - /opt/musetalk/models:/opt/musetalk/repo/MuseTalk/models
    environment:
      # 自动选择空闲GPU（在 start.sh 中实现），如需固定手动覆盖为 0/1
      CUDA_VISIBLE_DEVICES: "auto"
      OMP_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      HF_HOME: "/root/.cache/huggingface"
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb=256"