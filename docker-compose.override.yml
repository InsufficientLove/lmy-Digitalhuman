version: "3.9"

services:
  musetalk-python:
    # 暴露Python服务端口
    ports:
      - "28888:28888"
    volumes:
      # 将宿主机模型目录直接映射为代码期望的 ./models（/opt/musetalk/repo/MuseTalk/models）
      - /opt/musetalk/models:/opt/musetalk/repo/MuseTalk/models
      # 将脚本目录挂载进容器，便于直接执行下载脚本
      - ./scripts:/opt/musetalk/repo/scripts:ro
    environment:
      # 自动选择空闲GPU（在 start.sh 中实现），如需固定手动覆盖为 0/1
      CUDA_VISIBLE_DEVICES: "auto"
      OMP_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      HF_HOME: "/root/.cache/huggingface"
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb=256"

  lmy-digitalhuman:
    # 暴露.NET服务端口以便从主机访问
    ports:
      - "5000:5000"