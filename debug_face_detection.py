# -*- coding: utf-8 -*-
"""
è°ƒè¯•é¢éƒ¨æ£€æµ‹è„šæœ¬
ä¸“é—¨ç”¨æ¥æµ‹è¯•å°å“ˆ.jpgçš„é¢éƒ¨æ£€æµ‹é—®é¢˜
"""
import cv2
import numpy as np
import os
import sys

def test_image_reading(image_path):
    """æµ‹è¯•å›¾ç‰‡è¯»å–"""
    print(f"ğŸ” æµ‹è¯•å›¾ç‰‡è¯»å–: {image_path}")
    print(f"ğŸ“ æ–‡ä»¶å­˜åœ¨: {os.path.exists(image_path)}")
    
    if not os.path.exists(image_path):
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return None
    
    # æ–¹æ³•1: ç›´æ¥è¯»å–
    print("æ–¹æ³•1: cv2.imread ç›´æ¥è¯»å–")
    img1 = cv2.imread(image_path)
    if img1 is not None:
        print(f"âœ… ç›´æ¥è¯»å–æˆåŠŸï¼Œå°ºå¯¸: {img1.shape}")
    else:
        print("âŒ ç›´æ¥è¯»å–å¤±è´¥")
    
    # æ–¹æ³•2: numpyè¯»å–ï¼ˆå¤„ç†ä¸­æ–‡è·¯å¾„ï¼‰
    print("æ–¹æ³•2: numpy + cv2.imdecode è¯»å–")
    try:
        with open(image_path, 'rb') as f:
            img_data = f.read()
        img_array = np.frombuffer(img_data, np.uint8)
        img2 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        if img2 is not None:
            print(f"âœ… numpyè¯»å–æˆåŠŸï¼Œå°ºå¯¸: {img2.shape}")
            return img2
        else:
            print("âŒ numpyè¯»å–å¤±è´¥")
    except Exception as e:
        print(f"âŒ numpyè¯»å–å¼‚å¸¸: {e}")
    
    return img1 if img1 is not None else None

def test_opencv_face_detection(img):
    """æµ‹è¯•OpenCVé¢éƒ¨æ£€æµ‹"""
    print("ğŸ” æµ‹è¯•OpenCVé¢éƒ¨æ£€æµ‹")
    
    # åˆå§‹åŒ–é¢éƒ¨æ£€æµ‹å™¨
    try:
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        if face_cascade.empty():
            print("âŒ Haarçº§è”åˆ†ç±»å™¨åŠ è½½å¤±è´¥")
            return []
        print("âœ… Haarçº§è”åˆ†ç±»å™¨åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é¢éƒ¨æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return []
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    print(f"âœ… ç°åº¦å›¾è½¬æ¢æˆåŠŸï¼Œå°ºå¯¸: {gray.shape}")
    
    # å¤šç§å‚æ•°å°è¯•é¢éƒ¨æ£€æµ‹
    detection_params = [
        {"scaleFactor": 1.1, "minNeighbors": 5, "minSize": (30, 30)},
        {"scaleFactor": 1.05, "minNeighbors": 3, "minSize": (20, 20)},
        {"scaleFactor": 1.2, "minNeighbors": 7, "minSize": (50, 50)},
        {"scaleFactor": 1.3, "minNeighbors": 4, "minSize": (40, 40)},
    ]
    
    for i, params in enumerate(detection_params):
        print(f"ğŸ” å°è¯•å‚æ•°ç»„åˆ {i+1}: {params}")
        faces = face_cascade.detectMultiScale(gray, **params)
        print(f"æ£€æµ‹åˆ° {len(faces)} ä¸ªé¢éƒ¨")
        
        if len(faces) > 0:
            print("âœ… é¢éƒ¨æ£€æµ‹æˆåŠŸï¼")
            for j, (x, y, w, h) in enumerate(faces):
                print(f"  é¢éƒ¨ {j+1}: x={x}, y={y}, w={w}, h={h}")
                # è®¡ç®—é¢éƒ¨ä¸­å¿ƒå’Œé¢ç§¯
                center_x, center_y = x + w//2, y + h//2
                area = w * h
                print(f"  ä¸­å¿ƒ: ({center_x}, {center_y}), é¢ç§¯: {area}")
            
            # é€‰æ‹©æœ€å¤§çš„é¢éƒ¨
            largest_face = max(faces, key=lambda rect: rect[2] * rect[3])
            x, y, w, h = largest_face
            print(f"ğŸ¯ æœ€å¤§é¢éƒ¨: x={x}, y={y}, w={w}, h={h}")
            
            # æ‰©å±•é¢éƒ¨åŒºåŸŸ
            expand_ratio = 0.3
            expand_w = int(w * expand_ratio)
            expand_h = int(h * expand_ratio)
            
            x1 = max(0, x - expand_w)
            y1 = max(0, y - expand_h)
            x2 = min(img.shape[1], x + w + expand_w)
            y2 = min(img.shape[0], y + h + expand_h)
            
            # ç¡®ä¿æ˜¯æ­£æ–¹å½¢
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            size = max(x2 - x1, y2 - y1)
            half_size = size // 2
            
            x1 = max(0, center_x - half_size)
            y1 = max(0, center_y - half_size)
            x2 = min(img.shape[1], center_x + half_size)
            y2 = min(img.shape[0], center_y + half_size)
            
            actual_size = min(x2 - x1, y2 - y1)
            x2 = x1 + actual_size
            y2 = y1 + actual_size
            
            print(f"ğŸ¯ æœ€ç»ˆåæ ‡: ({x1}, {y1}, {x2}, {y2}), å°ºå¯¸: {actual_size}x{actual_size}")
            
            return [(x1, y1, x2, y2)]
    
    print("âŒ æ‰€æœ‰å‚æ•°ç»„åˆéƒ½æœªæ£€æµ‹åˆ°é¢éƒ¨")
    return []

def test_fallback_method(img):
    """æµ‹è¯•å¤‡ç”¨æ–¹æ³•"""
    print("ğŸ” æµ‹è¯•å¤‡ç”¨é¢éƒ¨åŒºåŸŸè®¡ç®—")
    
    h, w = img.shape[:2]
    print(f"å›¾ç‰‡å°ºå¯¸: {w}x{h}")
    
    # åŸæ¥çš„å¤‡ç”¨æ–¹æ³•
    face_size = min(w, h) // 2
    center_x, center_y = w // 2, h // 2
    half_size = face_size // 2
    x1 = max(0, center_x - half_size)
    y1 = max(0, center_y - half_size)
    x2 = min(w, center_x + half_size)
    y2 = min(h, center_y + half_size)
    size = min(x2 - x1, y2 - y1)
    x2, y2 = x1 + size, y1 + size
    
    print(f"å¤‡ç”¨æ–¹æ³•åæ ‡: ({x1}, {y1}, {x2}, {y2}), å°ºå¯¸: {size}x{size}")
    
    # æ”¹è¿›çš„å¤‡ç”¨æ–¹æ³• - å‡è®¾é¢éƒ¨åœ¨ä¸ŠåŠéƒ¨åˆ†ä¸­å¤®
    face_ratio = 0.6  # é¢éƒ¨å å›¾ç‰‡çš„æ¯”ä¾‹
    face_size = int(min(w, h) * face_ratio)
    
    # é¢éƒ¨é€šå¸¸åœ¨å›¾ç‰‡çš„ä¸ŠåŠéƒ¨åˆ†
    center_x = w // 2
    center_y = int(h * 0.4)  # é¢éƒ¨ä¸­å¿ƒåœ¨å›¾ç‰‡40%é«˜åº¦å¤„
    
    half_size = face_size // 2
    x1_new = max(0, center_x - half_size)
    y1_new = max(0, center_y - half_size)
    x2_new = min(w, center_x + half_size)
    y2_new = min(h, center_y + half_size)
    
    # ç¡®ä¿æ˜¯æ­£æ–¹å½¢
    size_new = min(x2_new - x1_new, y2_new - y1_new)
    x2_new = x1_new + size_new
    y2_new = y1_new + size_new
    
    print(f"æ”¹è¿›å¤‡ç”¨æ–¹æ³•åæ ‡: ({x1_new}, {y1_new}, {x2_new}, {y2_new}), å°ºå¯¸: {size_new}x{size_new}")
    
    return [(x1, y1, x2, y2)], [(x1_new, y1_new, x2_new, y2_new)]

def save_debug_image(img, coords_list, output_path):
    """ä¿å­˜è°ƒè¯•å›¾ç‰‡ï¼Œæ ‡è®°é¢éƒ¨åŒºåŸŸ"""
    debug_img = img.copy()
    
    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]
    
    for i, coords in enumerate(coords_list):
        color = colors[i % len(colors)]
        for x1, y1, x2, y2 in coords:
            cv2.rectangle(debug_img, (x1, y1), (x2, y2), color, 2)
            cv2.putText(debug_img, f"Method {i+1}", (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    cv2.imwrite(output_path, debug_img)
    print(f"âœ… è°ƒè¯•å›¾ç‰‡å·²ä¿å­˜: {output_path}")

def main():
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„
    image_path = r"C:\Users\Administrator\Desktop\digitalhuman\lmy-Digitalhuman\LmyDigitalHuman\wwwroot\templates\å°å“ˆ.jpg"
    
    print("=" * 60)
    print("ğŸ” é¢éƒ¨æ£€æµ‹è°ƒè¯•è„šæœ¬")
    print("=" * 60)
    
    # 1. æµ‹è¯•å›¾ç‰‡è¯»å–
    img = test_image_reading(image_path)
    if img is None:
        print("âŒ æ— æ³•è¯»å–å›¾ç‰‡ï¼Œé€€å‡ºè°ƒè¯•")
        return
    
    print("\n" + "=" * 60)
    
    # 2. æµ‹è¯•OpenCVé¢éƒ¨æ£€æµ‹
    opencv_coords = test_opencv_face_detection(img)
    
    print("\n" + "=" * 60)
    
    # 3. æµ‹è¯•å¤‡ç”¨æ–¹æ³•
    fallback_coords, improved_coords = test_fallback_method(img)
    
    print("\n" + "=" * 60)
    
    # 4. ä¿å­˜è°ƒè¯•å›¾ç‰‡
    all_coords = []
    if opencv_coords:
        all_coords.append(opencv_coords)
    all_coords.append(fallback_coords)
    all_coords.append(improved_coords)
    
    debug_output = "debug_face_detection.jpg"
    save_debug_image(img, all_coords, debug_output)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è°ƒè¯•å®Œæˆï¼")
    print("è¯·æŸ¥çœ‹ debug_face_detection.jpg æ¥çœ‹é¢éƒ¨æ£€æµ‹ç»“æœ")
    print("=" * 60)

if __name__ == "__main__":
    main()