#!/usr/bin/env python3
"""
åˆ†æ®µå¤„ç†å™¨ - ä¼ªå®æ—¶æµå¼å¤„ç†
å°†éŸ³é¢‘åˆ†æˆ1-2ç§’ç‰‡æ®µè¿›è¡Œå¿«é€Ÿå¤„ç†
"""

import os
import sys
import time
import json
import asyncio
import librosa
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class SegmentProcessor:
    """åˆ†æ®µå¤„ç†å™¨ - å¤ç”¨ç¦»çº¿æ¨ç†ä¼˜åŒ–"""
    
    def __init__(self):
        self.service = None
        self.template_cache = {}
        # ä¼˜åŒ–çš„åˆ†æ®µå‚æ•° - æ›´çŸ­çš„æ®µä»¥é™ä½å»¶è¿Ÿ
        self.segment_duration = 1.0  # æ¯æ®µæ ‡å‡†1ç§’ï¼ˆå¹³è¡¡å»¶è¿Ÿå’Œæ•ˆç‡ï¼‰
        self.max_segment_duration = 1.5  # æœ€é•¿1.5ç§’
        self.min_segment_duration = 0.3  # æœ€çŸ­0.3ç§’ï¼ˆé¿å…å¤ªç¢ç‰‡åŒ–ï¼‰
        
    def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        from offline.batch_inference import UltraFastMuseTalkService
        
        print("ğŸš€ åˆå§‹åŒ–åˆ†æ®µå¤„ç†å™¨...")
        self.service = UltraFastMuseTalkService()
        self.service.initialize_models()
        print("âœ… åˆ†æ®µå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def split_audio_to_segments(self, audio_path: str) -> List[Dict]:
        """å°†éŸ³é¢‘åˆ†å‰²æˆå°æ®µ"""
        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(audio_path, sr=16000)
            total_duration = len(audio) / sr
            
            segments = []
            current_pos = 0
            segment_index = 0
            
            while current_pos < len(audio):
                # è®¡ç®—æ®µé•¿åº¦
                segment_samples = int(self.segment_duration * sr)
                end_pos = min(current_pos + segment_samples, len(audio))
                
                # æå–æ®µ
                segment_audio = audio[current_pos:end_pos]
                segment_duration = len(segment_audio) / sr
                
                # è·³è¿‡å¤ªçŸ­çš„æ®µ
                if segment_duration < self.min_segment_duration:
                    break
                
                # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                segment_path = f"/tmp/segment_{segment_index}.wav"
                import soundfile as sf
                sf.write(segment_path, segment_audio, sr)
                
                segments.append({
                    'index': segment_index,
                    'path': segment_path,
                    'start_time': current_pos / sr,
                    'duration': segment_duration,
                    'frames': int(segment_duration * 25)  # 25fps
                })
                
                current_pos = end_pos
                segment_index += 1
            
            print(f"ğŸ“Š éŸ³é¢‘åˆ†å‰²: {total_duration:.1f}ç§’ -> {len(segments)}æ®µ")
            return segments
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆ†å‰²å¤±è´¥: {e}")
            return []
    
    def process_segment(
        self, 
        template_id: str,
        segment_info: Dict,
        skip_frames: int = 1
    ) -> Dict:
        """å¤„ç†å•ä¸ªéŸ³é¢‘ç‰‡æ®µ - ä¼˜åŒ–ç‰ˆ"""
        try:
            start_time = time.time()
            
            # ä¼˜åŒ–çš„æ‰¹æ¬¡å¤§å°ç­–ç•¥
            num_frames = segment_info['frames']
            if num_frames <= 12:  # 0.5ç§’ä»¥å†… - æé€Ÿæ¨¡å¼
                batch_size = min(num_frames, 6)
                skip_frames = 1
            elif num_frames <= 25:  # 1ç§’ä»¥å†… - å¿«é€Ÿæ¨¡å¼
                batch_size = min(num_frames, 12)
                skip_frames = 2
            elif num_frames <= 50:  # 2ç§’ä»¥å†… - æ ‡å‡†æ¨¡å¼
                batch_size = 16
                skip_frames = 2
            else:  # 2ç§’ä»¥ä¸Š - è·³å¸§æ¨¡å¼
                batch_size = 20
                skip_frames = 3
            
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            output_path = f"/tmp/segment_{template_id}_{segment_info['index']}.mp4"
            
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get('MUSE_TEMPLATE_CACHE_DIR', '/opt/musetalk/template_cache')
            
            # è°ƒç”¨ç¦»çº¿æ¨ç†ï¼ˆå¤ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼‰
            success = self.service.ultra_fast_inference_parallel(
                template_id=template_id,
                audio_path=segment_info['path'],
                output_path=output_path,
                cache_dir=cache_dir,
                batch_size=batch_size,
                skip_frames=skip_frames,
                streaming=True,  # æ ‡è®°ä¸ºæµå¼æ¨¡å¼
                auto_adjust=True  # è‡ªåŠ¨è°ƒæ•´é¿å…OOM
            )
            
            process_time = time.time() - start_time
            
            return {
                'success': success,
                'index': segment_info['index'],
                'path': output_path if success else None,
                'duration': segment_info['duration'],
                'frames': num_frames,
                'process_time': process_time,
                'start_time': segment_info['start_time']
            }
            
        except Exception as e:
            print(f"âŒ æ®µå¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'index': segment_info['index'],
                'error': str(e)
            }
    
    async def process_stream(
        self,
        template_id: str,
        audio_path: str,
        callback=None
    ):
        """æµå¼å¤„ç†éŸ³é¢‘"""
        try:
            # åˆ†å‰²éŸ³é¢‘
            segments = self.split_audio_to_segments(audio_path)
            if not segments:
                print("âŒ éŸ³é¢‘åˆ†å‰²å¤±è´¥")
                return
            
            # é€æ®µå¤„ç†
            for segment in segments:
                print(f"âš¡ å¤„ç†æ®µ {segment['index']+1}/{len(segments)}")
                
                result = self.process_segment(template_id, segment)
                
                if result['success']:
                    print(f"âœ… æ®µ {result['index']} å®Œæˆ: {result['process_time']:.1f}ç§’")
                    
                    # å›è°ƒé€šçŸ¥
                    if callback:
                        await callback(result)
                else:
                    print(f"âŒ æ®µ {result['index']} å¤±è´¥")
                    
        except Exception as e:
            print(f"âŒ æµå¼å¤„ç†å¤±è´¥: {e}")

    def cleanup_segments(self, prefix: str = "segment_"):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            import glob
            for file in glob.glob(f"/tmp/{prefix}*.wav"):
                os.remove(file)
            for file in glob.glob(f"/tmp/{prefix}*.mp4"):
                os.remove(file)
            print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å¤±è´¥: {e}")


class StreamingServer:
    """æµå¼æœåŠ¡å™¨ - å¤„ç†WebSocketè¿æ¥"""
    
    def __init__(self):
        self.processor = SegmentProcessor()
        self.connections = {}
        
    async def handle_connection(self, websocket, path):
        """å¤„ç†WebSocketè¿æ¥"""
        connection_id = id(websocket)
        self.connections[connection_id] = websocket
        
        try:
            async for message in websocket:
                data = json.loads(message)
                
                if data['command'] == 'start_stream':
                    await self.start_streaming(
                        websocket,
                        data['template_id'],
                        data['audio_path']
                    )
                    
        except Exception as e:
            print(f"âŒ è¿æ¥é”™è¯¯: {e}")
        finally:
            del self.connections[connection_id]
    
    async def start_streaming(self, websocket, template_id, audio_path):
        """å¼€å§‹æµå¼å¤„ç†"""
        
        async def send_segment(result):
            """å‘é€è§†é¢‘æ®µåˆ°å®¢æˆ·ç«¯"""
            await websocket.send(json.dumps({
                'type': 'segment',
                'data': result
            }))
        
        # å¤„ç†æµ
        await self.processor.process_stream(
            template_id,
            audio_path,
            callback=send_segment
        )
        
        # å‘é€å®Œæˆä¿¡å·
        await websocket.send(json.dumps({
            'type': 'complete'
        }))


def main():
    """æµ‹è¯•å…¥å£"""
    import argparse
    parser = argparse.ArgumentParser(description='åˆ†æ®µå¤„ç†å™¨')
    parser.add_argument('--template_id', required=True, help='æ¨¡æ¿ID')
    parser.add_argument('--audio_path', required=True, help='éŸ³é¢‘è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    processor = SegmentProcessor()
    processor.initialize()
    
    if args.test:
        # æµ‹è¯•åˆ†å‰²
        segments = processor.split_audio_to_segments(args.audio_path)
        print(f"åˆ†å‰²ç»“æœ: {len(segments)}æ®µ")
        
        # æµ‹è¯•å¤„ç†ç¬¬ä¸€æ®µ
        if segments:
            result = processor.process_segment(args.template_id, segments[0])
            print(f"å¤„ç†ç»“æœ: {result}")
    else:
        # è¿è¡Œæµå¼å¤„ç†
        asyncio.run(processor.process_stream(
            args.template_id,
            args.audio_path
        ))
    
    processor.cleanup_segments()


if __name__ == "__main__":
    main()