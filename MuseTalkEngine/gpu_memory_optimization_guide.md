# GPU内存优化指南

## 问题诊断

您遇到的问题是：
1. **CUDA内存不足**：尝试分配48.90 GiB内存，但GPU只有24GB
2. **GPU利用不均**：虽然有4个GPU，但推理时只使用了GPU 0

## 已实施的优化

### 1. 批次大小优化
- 将默认batch_size从16降低到4
- 这大幅减少了GPU内存需求

### 2. GPU负载均衡
- 修复了批次分配逻辑，确保使用所有4个GPU
- 添加了调试信息显示每个批次分配到哪个GPU

### 3. 内存管理优化
- 在CPU上生成数据，避免GPU0内存压力
- 推理前清理所有GPU内存
- 限制同时处理的批次数
- 定期清理GPU内存

### 4. 配置管理
- 创建了`gpu_config.py`配置文件
- 支持动态调整内存使用策略
- 添加了GPU内存监控功能

### 5. 面部解析修复
- 修复了面部解析返回值处理
- 改进了错误处理逻辑

## 使用建议

### 1. 调整批次大小
如果仍然遇到内存问题，可以进一步降低批次大小：
```python
# 在gpu_config.py中修改
'batch_size': {
    'default': 2,  # 从4降到2
}
```

### 2. 监控GPU使用
运行时会显示：
- 每个批次分配到的GPU
- GPU内存使用百分比
- 处理进度

### 3. 优化策略
- **短音频**（<10秒）：batch_size=4-6
- **中等音频**（10-30秒）：batch_size=2-4
- **长音频**（>30秒）：batch_size=1-2

### 4. 环境变量设置
可以通过环境变量进一步优化：
```bash
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
```

## 验证优化效果

1. **检查GPU分配**：
   - 应该看到类似输出：
   ```
   处理批次 0 -> GPU cuda:0
   处理批次 1 -> GPU cuda:1
   处理批次 2 -> GPU cuda:2
   处理批次 3 -> GPU cuda:3
   ```

2. **内存使用监控**：
   - 每个GPU的内存使用应该保持在80%以下

3. **性能提升**：
   - 4GPU并行应该比单GPU快3-4倍

## 故障排除

如果仍有问题：

1. **检查GPU状态**：
   ```bash
   nvidia-smi
   ```

2. **清理GPU内存**：
   ```python
   import torch
   torch.cuda.empty_cache()
   ```

3. **降低并发数**：
   修改`max_concurrent_batches`参数

4. **使用更小的模型**：
   考虑使用量化或精简版模型

## 性能基准

在4x RTX 4090 (24GB)配置下的预期性能：
- batch_size=4：约30-40 FPS
- batch_size=2：约20-30 FPS
- batch_size=1：约10-20 FPS

实际性能取决于：
- 音频长度
- 视频分辨率
- GPU型号和数量