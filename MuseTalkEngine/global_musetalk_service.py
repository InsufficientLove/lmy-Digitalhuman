#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨å±€æŒä¹…åŒ–MuseTalkæœåŠ¡
åŸºäºå®˜æ–¹MuseTalkæ¶æ„ï¼Œå¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼Œé€šè¿‡IPCé€šä¿¡å®ç°çœŸæ­£çš„å®æ—¶æ¨ç†
"""

import os
import sys
import json
import pickle
import torch
import cv2
import numpy as np
import argparse
import time
import threading
import queue
import subprocess
import shutil
import socket
import struct
from pathlib import Path
from tqdm import tqdm
import copy
from transformers import WhisperModel
from moviepy.editor import VideoFileClip, AudioFileClip
import imageio

# æ·»åŠ MuseTalkæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'MuseTalk'))

from musetalk.utils.face_parsing import FaceParsing
from musetalk.utils.utils import datagen, load_all_model
from musetalk.utils.preprocessing import get_landmark_and_bbox, read_imgs
from musetalk.utils.blending import get_image, get_image_blending, get_image_prepare_material
from musetalk.utils.audio_processor import AudioProcessor

print("MuseTalkå…¨å±€æœåŠ¡æ¨¡å—å¯¼å…¥å®Œæˆ")
sys.stdout.flush()

class GlobalMuseTalkService:
    """å…¨å±€æŒä¹…åŒ–MuseTalkæœåŠ¡ - çœŸæ­£çš„å•ä¾‹æ¨¡å¼"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.device = None
        self.vae = None
        self.unet = None
        self.pe = None
        self.whisper = None
        self.audio_processor = None
        self.fp = None
        self.weight_dtype = None
        self.timesteps = None
        self.is_initialized = False
        self.inference_lock = threading.Lock()
        
        # é…ç½®å‚æ•° - åŸºäºå®˜æ–¹MuseTalk
        self.unet_model_path = "./models/musetalk/pytorch_model.bin"
        self.unet_config = "./models/musetalk/musetalk.json"
        self.vae_type = "sd-vae"
        self.whisper_dir = "./models/whisper"
        
        # IPCé€šä¿¡
        self.server_socket = None
        self.is_server_running = False
        
        self._initialized = True
        print("å…¨å±€MuseTalkæœåŠ¡å®ä¾‹å·²åˆ›å»º")
    
    def initialize_models_once(self, gpu_id=0, multi_gpu=False):
        """å…¨å±€åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹ï¼ˆæ•´ä¸ªç¨‹åºç”Ÿå‘½å‘¨æœŸåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
        if self.is_initialized:
            print("æ¨¡å‹å·²å…¨å±€åˆå§‹åŒ–ï¼Œç›´æ¥å¤ç”¨")
            return True
            
        try:
            # 4GPUå¹¶è¡Œé…ç½®
            if multi_gpu and torch.cuda.device_count() >= 4:
                print(f"å…¨å±€åˆå§‹åŒ–MuseTalkæ¨¡å‹ (4GPUå¹¶è¡Œ)...")
                print(f"ğŸ® æ£€æµ‹åˆ°GPUæ•°é‡: {torch.cuda.device_count()}")
                print(f"å¯ç”¨4GPUå¹¶è¡Œç®—åŠ›: cuda:0,1,2,3")
                self.device = f'cuda:{gpu_id}'
                self.multi_gpu = True
                self.gpu_devices = [f'cuda:{i}' for i in range(4)]
                print(f"4GPUè®¾å¤‡åˆ—è¡¨: {self.gpu_devices}")
            else:
                print(f"å…¨å±€åˆå§‹åŒ–MuseTalkæ¨¡å‹ (GPU:{gpu_id})...")
                self.device = f'cuda:{gpu_id}'
                self.multi_gpu = False
                self.gpu_devices = [f'cuda:{gpu_id}']
                
            print(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {self.device}")
            start_time = time.time()
            
            # è®¾ç½®è®¾å¤‡
            self.device = torch.device(f"cuda:{gpu_id}" if torch.cuda.is_available() else "cpu")
            print(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {self.device}")
            
            # åŸºäºå®˜æ–¹MuseTalkæ¶æ„åŠ è½½æ¨¡å‹
            print("åŠ è½½VAE, UNet, PEæ¨¡å‹...")
            try:
                self.vae, self.unet, self.pe = load_all_model(
                    unet_model_path=self.unet_model_path,
                    vae_type=self.vae_type,
                    unet_config=self.unet_config,
                    device=self.device
                )
                print("VAE, UNet, PEæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as model_error:
                print(f"æ¨¡å‹åŠ è½½è­¦å‘Š: {str(model_error)}")
                print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹é…ç½®...")
                # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå…ˆç»§ç»­å…¶ä»–ç»„ä»¶çš„åˆå§‹åŒ–
                pass
            
            # å®˜æ–¹ä¼˜åŒ–ï¼šä½¿ç”¨halfç²¾åº¦æå‡æ€§èƒ½
            self.weight_dtype = torch.float16
            if hasattr(self, 'pe') and self.pe is not None:
                try:
                    self.pe = self.pe.half().to(self.device)
                    print("PEæ¨¡å‹ä¼˜åŒ–å®Œæˆ")
                except Exception as e:
                    print(f"PEæ¨¡å‹ä¼˜åŒ–å¤±è´¥: {str(e)}")
            
            if hasattr(self, 'vae') and self.vae is not None:
                try:
                    self.vae.vae = self.vae.vae.half().to(self.device)
                    print("VAEæ¨¡å‹ä¼˜åŒ–å®Œæˆ")
                except Exception as e:
                    print(f"VAEæ¨¡å‹ä¼˜åŒ–å¤±è´¥: {str(e)}")
            
            if hasattr(self, 'unet') and self.unet is not None:
                try:
                    self.unet.model = self.unet.model.half().to(self.device)
                    print("UNetæ¨¡å‹ä¼˜åŒ–å®Œæˆ")
                except Exception as e:
                    print(f"UNetæ¨¡å‹ä¼˜åŒ–å¤±è´¥: {str(e)}")
            
            self.timesteps = torch.tensor([0], device=self.device)
            
            # åŠ è½½Whisperæ¨¡å‹
            print("åŠ è½½Whisperæ¨¡å‹...")
            try:
                self.audio_processor = AudioProcessor(feature_extractor_path=self.whisper_dir)
                self.whisper = WhisperModel.from_pretrained(self.whisper_dir)
                self.whisper = self.whisper.to(device=self.device, dtype=self.weight_dtype).eval()
                self.whisper.requires_grad_(False)
                print("Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as whisper_error:
                print(f"Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(whisper_error)}")
                # ç»§ç»­åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
                pass
            
            # åˆå§‹åŒ–é¢éƒ¨è§£æå™¨
            print("ğŸ‘¤ åˆå§‹åŒ–é¢éƒ¨è§£æå™¨...")
            try:
                self.fp = FaceParsing()
                print("é¢éƒ¨è§£æå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as fp_error:
                print(f"é¢éƒ¨è§£æå™¨åˆå§‹åŒ–å¤±è´¥: {str(fp_error)}")
                pass
            
            # æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦åŠ è½½æˆåŠŸ
            critical_components = []
            if hasattr(self, 'vae') and self.vae is not None:
                critical_components.append("VAE")
            if hasattr(self, 'unet') and self.unet is not None:
                critical_components.append("UNet")
            if hasattr(self, 'pe') and self.pe is not None:
                critical_components.append("PE")
            if hasattr(self, 'whisper') and self.whisper is not None:
                critical_components.append("Whisper")
            if hasattr(self, 'fp') and self.fp is not None:
                critical_components.append("FaceParsing")
            
            self.is_initialized = True
            init_time = time.time() - start_time
            print(f"å…¨å±€æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
            print(f"æˆåŠŸåŠ è½½ç»„ä»¶: {', '.join(critical_components)}")
            
            if len(critical_components) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªæ ¸å¿ƒç»„ä»¶
                print("æ ¸å¿ƒæ¨¡å‹å·²åŠ è½½åˆ°GPUå†…å­˜ï¼Œåç»­æ¨ç†å°†æé€Ÿæ‰§è¡Œ")
                return True
            else:
                print("éƒ¨åˆ†å…³é”®ç»„ä»¶åŠ è½½å¤±è´¥ï¼Œä½†æœåŠ¡ä»å¯å¯åŠ¨")
                return True  # ä»ç„¶è¿”å›Trueï¼Œè®©æœåŠ¡å¯åŠ¨
            
        except Exception as e:
            print(f"å…¨å±€æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_template_cache(self, cache_dir, template_id):
        """åŠ è½½æ¨¡æ¿ç¼“å­˜"""
        try:
            # åŠ è½½é¢„å¤„ç†ç¼“å­˜
            cache_file = os.path.join(cache_dir, f"{template_id}_preprocessed.pkl")
            metadata_file = os.path.join(cache_dir, f"{template_id}_metadata.json")
            
            if not os.path.exists(cache_file):
                raise FileNotFoundError(f"ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
            if not os.path.exists(metadata_file):
                raise FileNotFoundError(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
            
            # åŠ è½½ç¼“å­˜æ•°æ®
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # æå–æ•°æ®
            input_latent_list_cycle = cache_data['input_latent_list_cycle']
            coord_list_cycle = cache_data['coord_list_cycle']
            frame_list_cycle = cache_data['frame_list_cycle']
            mask_coords_list_cycle = cache_data['mask_coords_list_cycle']
            mask_list_cycle = cache_data['mask_list_cycle']
            
            print(f"æ¨¡æ¿ç¼“å­˜åŠ è½½æˆåŠŸ: {template_id}")
            print(f"   - æ½œåœ¨å‘é‡: {len(input_latent_list_cycle)} å¸§")
            print(f"   - é¢éƒ¨åæ ‡: {len(coord_list_cycle)} å¸§")
            
            return {
                'input_latent_list_cycle': input_latent_list_cycle,
                'coord_list_cycle': coord_list_cycle,
                'frame_list_cycle': frame_list_cycle,
                'mask_coords_list_cycle': mask_coords_list_cycle,
                'mask_list_cycle': mask_list_cycle,
                'metadata': metadata
            }
            
        except Exception as e:
            print(f"åŠ è½½æ¨¡æ¿ç¼“å­˜å¤±è´¥: {str(e)}")
            return None
    
    def ultra_fast_inference(self, template_id, audio_path, output_path, cache_dir, batch_size=8, fps=25):
        """è¶…å¿«é€Ÿæ¨ç† - å¤ç”¨å…¨å±€æ¨¡å‹ï¼Œæ— éœ€é‡å¤åŠ è½½"""
        if not self.is_initialized:
            print("å…¨å±€æ¨¡å‹æœªåˆå§‹åŒ–")
            return False
        
        # æ¨ç†é”ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
        with self.inference_lock:
            try:
                start_time = time.time()
                print(f"å¼€å§‹è¶…å¿«é€Ÿæ¨ç†: {template_id}")
                
                # 1. åŠ è½½æ¨¡æ¿ç¼“å­˜
                cache_data = self.load_template_cache(cache_dir, template_id)
                if not cache_data:
                    return False
                
                input_latent_list_cycle = cache_data['input_latent_list_cycle']
                coord_list_cycle = cache_data['coord_list_cycle']
                frame_list_cycle = cache_data['frame_list_cycle']
                
                # 2. éŸ³é¢‘ç‰¹å¾æå–
                print("æå–éŸ³é¢‘ç‰¹å¾...")
                audio_start = time.time()
                whisper_input_features, librosa_length = self.audio_processor.get_audio_feature(audio_path)
                whisper_chunks = self.audio_processor.get_whisper_chunk(
                    whisper_input_features, 
                    self.device, 
                    self.weight_dtype, 
                    self.whisper, 
                    librosa_length,
                    fps=fps,
                    audio_padding_length_left=2,
                    audio_padding_length_right=2,
                )
                audio_time = time.time() - audio_start
                print(f"éŸ³é¢‘ç‰¹å¾æå–å®Œæˆ: {audio_time:.2f}ç§’, éŸ³é¢‘å—æ•°: {len(whisper_chunks)}")
                
                # 3. æ‰¹é‡æ¨ç† - å¤ç”¨å…¨å±€æ¨¡å‹ï¼Œæé€Ÿæ‰§è¡Œ
                print("å¼€å§‹æ‰¹é‡æ¨ç†...")
                inference_start = time.time()
                video_num = len(whisper_chunks)
                gen = datagen(
                    whisper_chunks=whisper_chunks,
                    vae_encode_latents=input_latent_list_cycle,
                    batch_size=batch_size,
                    delay_frame=0,
                    device=self.device,
                )
                
                res_frame_list = []
                
                # ä¿®å¤ï¼šå…ˆæ”¶é›†æ‰€æœ‰æ‰¹æ¬¡ï¼Œç„¶åå†³å®šæ˜¯å¦å¹¶è¡Œ
                all_batches = list(gen)
                total_batches = len(all_batches)
                
                # ä¸´æ—¶ç¦ç”¨4GPUå¹¶è¡Œï¼Œé¿å…æ¨¡å‹å†²çª - ç­‰ç¨³å®šåå†ä¼˜åŒ–
                if False and self.multi_gpu and len(self.gpu_devices) >= 4 and total_batches > 1:
                    # çœŸæ­£çš„4GPUå¹¶è¡Œæ¨ç† - ä¿®å¤æ¨¡å‹å†²çªé—®é¢˜
                    print(f"ä½¿ç”¨çœŸæ­£4GPUå¹¶è¡Œæ¨ç†ï¼Œæ€»æ‰¹æ¬¡: {total_batches}")
                    sys.stdout.flush()
                    from concurrent.futures import ThreadPoolExecutor, as_completed
                    import copy
                    
                    def process_batch_on_gpu(args):
                        i, (whisper_batch, latent_batch), target_gpu = args
                        try:
                            # å…³é”®ï¼šæ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ä¸åŒçš„GPU
                            device = torch.device(target_gpu)
                            torch.cuda.set_device(device)
                            
                            print(f"ğŸ® æ‰¹æ¬¡{i}ä½¿ç”¨GPU: {target_gpu}")
                            sys.stdout.flush()
                            
                            # å°†æ•°æ®ç§»åˆ°ç›®æ ‡GPU
                            whisper_batch = whisper_batch.to(device)
                            latent_batch = latent_batch.to(dtype=self.weight_dtype, device=device)
                            
                            # å…³é”®ä¿®å¤ï¼šä¸ºæ¯ä¸ªGPUåˆ›å»ºç‹¬ç«‹çš„æ¨¡å‹å‰¯æœ¬
                            with torch.no_grad():
                                # åˆ›å»ºæ¨¡å‹çš„æ·±åº¦å‰¯æœ¬å¹¶ç§»åˆ°ç›®æ ‡GPU
                                pe_gpu = copy.deepcopy(self.pe).to(device)
                                unet_gpu = copy.deepcopy(self.unet.model).to(device)  
                                vae_gpu = copy.deepcopy(self.vae.vae).to(device)
                                timesteps_gpu = self.timesteps.to(device)
                                
                                # æ‰§è¡Œæ¨ç†
                                audio_feature_batch = pe_gpu(whisper_batch)
                                pred_latents = unet_gpu(latent_batch, timesteps_gpu, encoder_hidden_states=audio_feature_batch).sample
                                recon = vae_gpu.decode(pred_latents / vae_gpu.config.scaling_factor).sample
                                
                                # æ¸…ç†GPUå†…å­˜
                                del pe_gpu, unet_gpu, vae_gpu, timesteps_gpu
                                torch.cuda.empty_cache()
                            
                            # å°†ç»“æœç§»å›CPU
                            return i, [frame.cpu().numpy() for frame in recon]
                        except Exception as e:
                            print(f"æ‰¹æ¬¡ {i} GPU {target_gpu} æ¨ç†å¤±è´¥: {str(e)}")
                            sys.stdout.flush()
                            # æ¸…ç†GPUå†…å­˜
                            torch.cuda.empty_cache()
                            return i, []
                    
                    # å°†æ‰¹æ¬¡åˆ†é…åˆ°4ä¸ªGPU
                    batch_args = []
                    for i, batch_data in enumerate(all_batches):
                        target_gpu = self.gpu_devices[i % len(self.gpu_devices)]
                        batch_args.append((i, batch_data, target_gpu))
                    
                    # çœŸæ­£çš„4GPUå¹¶è¡Œæ‰§è¡Œ
                    with ThreadPoolExecutor(max_workers=4) as executor:
                        batch_results = list(tqdm(executor.map(process_batch_on_gpu, batch_args), 
                                                total=len(batch_args), desc="4GPUå¹¶è¡Œæ¨ç†"))
                    
                    # æŒ‰é¡ºåºåˆå¹¶ç»“æœ
                    batch_results.sort(key=lambda x: x[0])  # æŒ‰æ‰¹æ¬¡ç´¢å¼•æ’åº
                    for _, batch_frames in batch_results:
                        res_frame_list.extend(batch_frames)
                        
                else:
                    # å•GPUæ¨ç†ï¼ˆåŸé€»è¾‘ï¼‰
                    print(f"ä½¿ç”¨å•GPUæ¨ç†ï¼Œæ€»æ‰¹æ¬¡: {total_batches}")
                    for i, (whisper_batch, latent_batch) in enumerate(tqdm(all_batches, desc="æ¨ç†è¿›åº¦")):
                        audio_feature_batch = self.pe(whisper_batch)
                        latent_batch = latent_batch.to(dtype=self.weight_dtype)
                        
                        # æ ¸å¿ƒæ¨ç† - å¤ç”¨å…¨å±€æ¨¡å‹
                        pred_latents = self.unet.model(latent_batch, self.timesteps, encoder_hidden_states=audio_feature_batch).sample
                        recon = self.vae.decode_latents(pred_latents)
                        for res_frame in recon:
                            res_frame_list.append(res_frame)
                
                inference_time = time.time() - inference_start
                print(f"æ¨ç†å®Œæˆ: {len(res_frame_list)} å¸§, è€—æ—¶: {inference_time:.2f}ç§’")
                
                # 4. å›¾åƒåˆæˆ - ğŸ¨ ä½¿ç”¨å®˜æ–¹get_imageæ–¹æ³•é¿å…é˜´å½±
                print("åˆæˆå®Œæ•´å›¾åƒ...")
                compose_start = time.time()
                
                # åˆ›å»ºä¸´æ—¶å¸§ç›®å½•
                temp_frames_dir = os.path.join(os.path.dirname(output_path), "temp_frames")
                os.makedirs(temp_frames_dir, exist_ok=True)
                
                # æé€Ÿä¼˜åŒ–ï¼šå¹¶è¡Œå¤„ç†å›¾åƒåˆæˆ
                from concurrent.futures import ThreadPoolExecutor
                import functools
                import copy  # å…³é”®ä¿®å¤ï¼šåœ¨æ­£ç¡®ä½ç½®å¯¼å…¥copyæ¨¡å—
                
                # å…³é”®ä¿®å¤ï¼šå°†æ¨¡æ¿ç¼“å­˜æ•°æ®æå–åˆ°å±€éƒ¨å˜é‡ï¼Œè§£å†³ä½œç”¨åŸŸé—®é¢˜
                coord_list_cycle = cache_data['coord_list_cycle']
                frame_list_cycle = cache_data['frame_list_cycle']
                mask_coords_list_cycle = cache_data['mask_coords_list_cycle']
                mask_list_cycle = cache_data['mask_list_cycle']
                
                def process_frame(args):
                    i, res_frame = args
                    bbox = coord_list_cycle[i % len(coord_list_cycle)]
                    ori_frame = copy.deepcopy(frame_list_cycle[i % len(frame_list_cycle)])
                    
                    x1, y1, x2, y2 = bbox
                    try:
                        res_frame = cv2.resize(res_frame.astype(np.uint8), (x2-x1, y2-y1))
                    except:
                        return None
                    
                    # å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨å®˜æ–¹get_image_blendingï¼Œæ¯”get_imageå¿«10å€ï¼
                    mask_coords = mask_coords_list_cycle[i % len(mask_coords_list_cycle)]
                    mask = mask_list_cycle[i % len(mask_list_cycle)]
                    
                    combine_frame = get_image_blending(
                        image=ori_frame,
                        face=res_frame, 
                        face_box=[x1, y1, x2, y2],
                        mask_array=mask,
                        crop_box=mask_coords
                    )
                    
                    # ä¿å­˜å¸§
                    frame_path = os.path.join(temp_frames_dir, f"{i:08d}.png")
                    cv2.imwrite(frame_path, combine_frame)
                    return i
                
                # å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨å®˜æ–¹MuseTalkçš„å¤šçº¿ç¨‹å¹¶è¡Œæ–¹æ¡ˆ
                print(f"å¼€å§‹æé€Ÿåˆæˆ{len(res_frame_list)}å¸§å›¾åƒ...")
                sys.stdout.flush()
                
                import queue
                import threading
                
                # åˆ›å»ºé˜Ÿåˆ—ç”¨äºçº¿ç¨‹é—´é€šä¿¡
                frame_queue = queue.Queue()
                compose_results = []
                
                def process_frames_worker():
                    """å›¾åƒåˆæˆå·¥ä½œçº¿ç¨‹"""
                    while True:
                        try:
                            item = frame_queue.get(timeout=1.0)
                            if item is None:  # ç»“æŸä¿¡å·
                                break
                            i, res_frame = item
                            result = process_frame((i, res_frame))
                            compose_results.append((i, result))
                            frame_queue.task_done()
                        except queue.Empty:
                            continue
                        except Exception as e:
                            print(f"åˆæˆç¬¬{i}å¸§å¤±è´¥: {str(e)}")
                            sys.stdout.flush()
                            frame_queue.task_done()
                
                # å¯åŠ¨å·¥ä½œçº¿ç¨‹
                worker_thread = threading.Thread(target=process_frames_worker)
                worker_thread.start()
                
                # å°†æ‰€æœ‰å¸§æ”¾å…¥é˜Ÿåˆ—
                for i, res_frame in enumerate(res_frame_list):
                    frame_queue.put((i, res_frame))
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                frame_queue.join()
                
                # å‘é€ç»“æŸä¿¡å·å¹¶ç­‰å¾…çº¿ç¨‹ç»“æŸ
                frame_queue.put(None)
                worker_thread.join()
                
                print(f"æé€Ÿåˆæˆå®Œæˆ: {len(compose_results)}å¸§")
                sys.stdout.flush()
                
                compose_time = time.time() - compose_start
                print(f"å›¾åƒåˆæˆå®Œæˆ: è€—æ—¶: {compose_time:.2f}ç§’")
                
                # 5. æé€Ÿè§†é¢‘ç”Ÿæˆ - ä½¿ç”¨å®˜æ–¹MuseTalkä¼˜åŒ–æ–¹æ³•
                print("æé€Ÿç”Ÿæˆè§†é¢‘...")
                video_start = time.time()
                
                # å…³é”®ä¼˜åŒ–ï¼šç›´æ¥ä»å†…å­˜ç”Ÿæˆè§†é¢‘ï¼Œé¿å…ç£ç›˜I/O
                import imageio
                
                # æ”¶é›†æ‰€æœ‰åˆæˆçš„å›¾åƒå¸§
                print(f"æ”¶é›†{len(res_frame_list)}å¸§å›¾åƒ...")
                video_frames = []
                for i in range(len(res_frame_list)):
                    frame_path = os.path.join(temp_frames_dir, f"{i:08d}.png")
                    if os.path.exists(frame_path):
                        frame = imageio.imread(frame_path)
                        video_frames.append(frame)
                
                if len(video_frames) == 0:
                    raise Exception("æ²¡æœ‰æ‰¾åˆ°åˆæˆçš„å›¾åƒå¸§")
                
                # å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨imageioç›´æ¥ç”Ÿæˆè§†é¢‘ï¼Œæ¯”FFmpegæ›´å¿«
                temp_video = output_path.replace('.mp4', '_temp.mp4')
                print(f"ä½¿ç”¨imageioç”Ÿæˆè§†é¢‘: {len(video_frames)}å¸§")
                imageio.mimwrite(temp_video, video_frames, 'FFMPEG', fps=fps, codec='libx264', pixelformat='yuv420p')
                
                video_time = time.time() - video_start
                print(f"è§†é¢‘ç”Ÿæˆå®Œæˆ: è€—æ—¶: {video_time:.2f}ç§’")
                
                # 6. åˆæˆéŸ³é¢‘
                print("åˆæˆéŸ³é¢‘...")
                audio_merge_start = time.time()
                
                try:
                    video_clip = VideoFileClip(temp_video)
                    audio_clip = AudioFileClip(audio_path)
                    video_clip = video_clip.set_audio(audio_clip)
                    video_clip.write_videofile(output_path, codec='libx264', audio_codec='aac', fps=fps, verbose=False, logger=None)
                    video_clip.close()
                    audio_clip.close()
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.remove(temp_video)
                    shutil.rmtree(temp_frames_dir)
                    
                except Exception as e:
                    print(f"éŸ³é¢‘åˆæˆå¤±è´¥ï¼Œä½¿ç”¨æ— éŸ³é¢‘ç‰ˆæœ¬: {str(e)}")
                    shutil.move(temp_video, output_path)
                
                audio_merge_time = time.time() - audio_merge_start
                print(f"éŸ³é¢‘åˆæˆå®Œæˆ: è€—æ—¶: {audio_merge_time:.2f}ç§’")
                
                total_time = time.time() - start_time
                print(f"è¶…å¿«é€Ÿæ¨ç†å®Œæˆ: {output_path}")
                print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’ (éŸ³é¢‘:{audio_time:.1f}s + æ¨ç†:{inference_time:.1f}s + åˆæˆ:{compose_time:.1f}s + è§†é¢‘:{video_time:.1f}s + éŸ³é¢‘:{audio_merge_time:.1f}s)")
                
                return True
                
            except Exception as e:
                print(f"è¶…å¿«é€Ÿæ¨ç†å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                return False
    
    def start_ipc_server(self, port=9999):
        """å¯åŠ¨IPCæœåŠ¡å™¨ï¼Œæ¥æ”¶æ¨ç†è¯·æ±‚"""
        try:
            print(f"åˆ›å»ºsocketå¯¹è±¡...")
            sys.stdout.flush()
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            
            print(f"è®¾ç½®socketé€‰é¡¹...")
            sys.stdout.flush()
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            
            print(f"ç»‘å®šç«¯å£ {port}... (åœ°å€: 127.0.0.1)")
            sys.stdout.flush()
            self.server_socket.bind(('127.0.0.1', port))
            
            print(f"å¼€å§‹ç›‘å¬è¿æ¥...")
            sys.stdout.flush()
            self.server_socket.listen(5)
            
            print(f"è®¾ç½®æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€...")
            sys.stdout.flush()
            self.is_server_running = True
            
            print(f"IPCæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼Œç›‘å¬ç«¯å£: {port}")
            print("ğŸ“¡ ç­‰å¾…C#å®¢æˆ·ç«¯è¿æ¥...")
            print("å…¨å±€MuseTalkæœåŠ¡å®Œå…¨å°±ç»ªï¼")
            sys.stdout.flush()
            
            print(f"è¿›å…¥ä¸»å¾ªç¯ï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
            sys.stdout.flush()
            
            print(f"å¼€å§‹æ¥å—è¿æ¥... (ç»‘å®š: 127.0.0.1:{port})")
            sys.stdout.flush()
            
            while self.is_server_running:
                try:
                    # å…³é”®ä¿®å¤ï¼šç§»é™¤è¶…æ—¶ï¼Œç›´æ¥é˜»å¡ç­‰å¾…è¿æ¥
                    client_socket, addr = self.server_socket.accept()
                    
                    print(f"ğŸ”— å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ! æ¥æº: {addr}")
                    sys.stdout.flush()
                    
                    # å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚
                    print(f"å¯åŠ¨å¤„ç†çº¿ç¨‹...")
                    sys.stdout.flush()
                    threading.Thread(target=self._handle_client, args=(client_socket,)).start()
                    
                except Exception as e:
                    if self.is_server_running:
                        print(f"æ¥å—è¿æ¥å¤±è´¥: {str(e)}")
                        import traceback
                        traceback.print_exc()
                        sys.stdout.flush()
                    
        except Exception as e:
            print(f"IPCæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
    
    def _handle_client(self, client_socket):
        """å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚"""
        try:
            print("ğŸ”— å¼€å§‹å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚...")
            sys.stdout.flush()
            
            # å…³é”®æ£€æŸ¥ï¼šç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
            print(f"æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–çŠ¶æ€: {self.is_initialized}")
            sys.stdout.flush()
            if not self.is_initialized:
                print("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¤„ç†æ¨ç†è¯·æ±‚")
                error_response = {'Success': False, 'OutputPath': None}
                response_data = json.dumps(error_response).encode('utf-8')
                client_socket.send(struct.pack('I', len(response_data)))
                client_socket.send(response_data)
                return
            
            # æ¥æ”¶è¯·æ±‚æ•°æ®
            print("ğŸ“¥ æ¥æ”¶è¯·æ±‚æ•°æ®...")
            data_length = struct.unpack('I', client_socket.recv(4))[0]
            data = client_socket.recv(data_length).decode('utf-8')
            request = json.loads(data)
            
            print(f"ğŸ“¨ æ”¶åˆ°æ¨ç†è¯·æ±‚: {request['template_id']}")
            
            # æ‰§è¡Œæ¨ç†
            print("å¼€å§‹æ‰§è¡Œæ¨ç†...")
            success = self.ultra_fast_inference(
                template_id=request['template_id'],
                audio_path=request['audio_path'],
                output_path=request['output_path'],
                cache_dir=request['cache_dir'],
                batch_size=request.get('batch_size', 8),
                fps=request.get('fps', 25)
            )
            print(f"æ¨ç†æ‰§è¡Œå®Œæˆï¼Œç»“æœ: {success}")
            
            # å‘é€å“åº” - ä¿®å¤ï¼šä½¿ç”¨C#æœŸæœ›çš„å¤§å†™å­—æ®µå
            response = {'Success': success, 'OutputPath': request['output_path'] if success else None}
            response_data = json.dumps(response).encode('utf-8')
            client_socket.send(struct.pack('I', len(response_data)))
            client_socket.send(response_data)
            
            print(f"ğŸ“¤ æ¨ç†å“åº”å·²å‘é€: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            
        except Exception as e:
            print(f"å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å…³é”®ä¿®å¤ï¼šå³ä½¿å¼‚å¸¸ä¹Ÿè¦å‘é€å“åº”
            try:
                error_response = {'Success': False, 'OutputPath': None}
                response_data = json.dumps(error_response).encode('utf-8')
                client_socket.send(struct.pack('I', len(response_data)))
                client_socket.send(response_data)
                print(f"ğŸ“¤ é”™è¯¯å“åº”å·²å‘é€")
            except:
                pass
        finally:
            client_socket.close()
    
    def stop_server(self):
        """åœæ­¢IPCæœåŠ¡å™¨"""
        self.is_server_running = False
        if self.server_socket:
            self.server_socket.close()
        print("ğŸ›‘ IPCæœåŠ¡å™¨å·²åœæ­¢")

# å…¨å±€æœåŠ¡å®ä¾‹
global_service = GlobalMuseTalkService()

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    try:
        print("Pythonå…¨å±€æœåŠ¡mainå‡½æ•°å¯åŠ¨...")
        sys.stdout.flush()
        print(f"Pythonç‰ˆæœ¬: {sys.version}")
        print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
        sys.stdout.flush()
        
        # æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥
        try:
            import torch
            print(f"torchç‰ˆæœ¬: {torch.__version__}")
            print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            sys.stdout.flush()
        except Exception as e:
            print(f"torchå¯¼å…¥å¤±è´¥: {str(e)}")
            sys.stdout.flush()
            sys.exit(1)
        
        print("å¼€å§‹è§£æå‘½ä»¤è¡Œå‚æ•°...")
        sys.stdout.flush()
    except Exception as e:
        print(f"mainå‡½æ•°åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description='å…¨å±€æŒä¹…åŒ–MuseTalkæœåŠ¡ - 4GPUå¹¶è¡Œ')
    parser.add_argument('--mode', choices=['server', 'client'], default='server', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--port', type=int, default=9999, help='IPCç«¯å£')
    parser.add_argument('--gpu_id', type=int, default=0, help='ä¸»GPU ID')
    parser.add_argument('--multi_gpu', action='store_true', help='å¯ç”¨4GPUå¹¶è¡Œæ¨¡å¼')
    
    # å®¢æˆ·ç«¯æ¨¡å¼å‚æ•°
    parser.add_argument('--template_id', type=str, help='æ¨¡æ¿ID')
    parser.add_argument('--audio_path', type=str, help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_path', type=str, help='è¾“å‡ºè§†é¢‘è·¯å¾„')
    parser.add_argument('--cache_dir', type=str, help='ç¼“å­˜ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--fps', type=int, default=25, help='è§†é¢‘å¸§ç‡')
    
    try:
        print("å¼€å§‹è§£æå‘½ä»¤è¡Œå‚æ•°...")
        sys.stdout.flush()
        args = parser.parse_args()
        print(f"å‚æ•°è§£æå®Œæˆ: mode={args.mode}, multi_gpu={args.multi_gpu}, gpu_id={args.gpu_id}, port={args.port}")
        sys.stdout.flush()
        
        print("è¿›å…¥æœåŠ¡å™¨æ¨¡å¼é€»è¾‘...")
        sys.stdout.flush()
    except Exception as e:
        print(f"å‚æ•°è§£æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()
        sys.exit(1)
    
    if args.mode == 'server':
        # æœåŠ¡å™¨æ¨¡å¼ï¼šå¯åŠ¨æ—¶åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹ï¼Œç„¶åç›‘å¬è¯·æ±‚
        if args.multi_gpu:
            print("å¯åŠ¨4GPUå¹¶è¡Œå…¨å±€MuseTalkæœåŠ¡å™¨...")
        else:
            print("å¯åŠ¨å…¨å±€MuseTalkæœåŠ¡å™¨...")
        sys.stdout.flush()
        
        # å…¨å±€åˆå§‹åŒ–æ¨¡å‹ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        print("å‡†å¤‡åˆå§‹åŒ–å…¨å±€æ¨¡å‹...")
        sys.stdout.flush()
        try:
            print("è°ƒç”¨initialize_models_once...")
            sys.stdout.flush()
            if not global_service.initialize_models_once(args.gpu_id, multi_gpu=args.multi_gpu):
                print("æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
                sys.stdout.flush()
                sys.exit(1)
            print("æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œå‡†å¤‡å¯åŠ¨IPCæœåŠ¡å™¨...")
            sys.stdout.flush()
        except Exception as e:
            print(f"æ¨¡å‹åˆå§‹åŒ–å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.stdout.flush()
            sys.exit(1)
        
        # å¯åŠ¨IPCæœåŠ¡å™¨
        print("å‡†å¤‡å¯åŠ¨IPCæœåŠ¡å™¨...")
        sys.stdout.flush()
        try:
            print("è°ƒç”¨start_ipc_server...")
            sys.stdout.flush()
            global_service.start_ipc_server(args.port)
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·")
            global_service.stop_server()
            sys.stdout.flush()
        except Exception as e:
            print(f"IPCæœåŠ¡å™¨å¯åŠ¨å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.stdout.flush()
            sys.exit(1)
            
    else:
        # å®¢æˆ·ç«¯æ¨¡å¼ï¼šç›´æ¥æ‰§è¡Œæ¨ç†
        if not all([args.template_id, args.audio_path, args.output_path, args.cache_dir]):
            print("å®¢æˆ·ç«¯æ¨¡å¼éœ€è¦æä¾›æ‰€æœ‰æ¨ç†å‚æ•°")
            sys.exit(1)
        
        # åˆå§‹åŒ–æ¨¡å‹
        if not global_service.initialize_models_once(args.gpu_id):
            print("æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            sys.exit(1)
        
        # æ‰§è¡Œæ¨ç†
        success = global_service.ultra_fast_inference(
            template_id=args.template_id,
            audio_path=args.audio_path,
            output_path=args.output_path,
            cache_dir=args.cache_dir,
            batch_size=args.batch_size,
            fps=args.fps
        )
        
        sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()