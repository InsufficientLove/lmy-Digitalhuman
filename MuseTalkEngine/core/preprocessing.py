#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Optimized Preprocessing V2
ä¼˜åŒ–ç‰ˆé¢„å¤„ç† - ä¿®å¤è„¸éƒ¨é˜´å½±é—®é¢˜ï¼Œæé€Ÿé¢„å¤„ç†
"""

import os
import sys
import json
import pickle
import torch
import cv2
import numpy as np
import argparse
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import copy
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ MuseTalkæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'MuseTalk'))
sys.path.append('/opt/musetalk/repo/MuseTalk')  # æ·»åŠ å®é™…çš„MuseTalkè·¯å¾„

try:
    from musetalk.utils.face_parsing import FaceParsing
    print("æˆåŠŸå¯¼å…¥FaceParsing")
    FACE_PARSING_AVAILABLE = True
except ImportError as e:
    print(f"æ— æ³•å¯¼å…¥FaceParsing: {e}")
    FACE_PARSING_AVAILABLE = False

from musetalk.utils.utils import load_all_model
from musetalk.utils.preprocessing import get_landmark_and_bbox, read_imgs
from musetalk.utils.blending import get_image_prepare_material
from musetalk.utils.audio_processor import AudioProcessor

# å®šä¹‰coord_placeholderå¸¸é‡
coord_placeholder = (0, 0, 0, 0)  # è¡¨ç¤ºæ— æ•ˆçš„è¾¹ç•Œæ¡†

print("Optimized Preprocessing V2 - æé€Ÿé¢„å¤„ç†å¼•æ“")

# ç®€å•çš„FaceParsingæ›¿ä»£å®ç°
class SimpleFaceParsing:
    """ç®€å•çš„é¢éƒ¨è§£ææ›¿ä»£å®ç°"""
    def __init__(self):
        pass
    
    def __call__(self, image, mode=None):
        """è¿”å›ä¸€ä¸ªé¢éƒ¨åˆ†å‰²mask
        è¿”å›å€¼åº”è¯¥æ˜¯åˆ†å‰²æ ‡ç­¾å›¾ï¼Œå…¶ä¸­ï¼š
        0 = èƒŒæ™¯
        1-5 = çš®è‚¤
        6-10 = çœ‰æ¯›ã€çœ¼ç›
        11-13 = é¼»å­ã€å˜´å·´
        14-17 = å¤´å‘
        """
        if isinstance(image, np.ndarray):
            h, w = image.shape[:2]
            # åˆ›å»ºåˆ†å‰²mask
            mask = np.zeros((h, w), dtype=np.uint8)
            
            # é¢éƒ¨ä¸»è¦åŒºåŸŸï¼ˆçš®è‚¤ï¼‰- ä½¿ç”¨æ ‡ç­¾1
            center_x, center_y = w // 2, h // 2
            
            # è„¸éƒ¨æ¤­åœ†ï¼ˆçš®è‚¤åŒºåŸŸï¼‰
            face_axes = (int(w * 0.35), int(h * 0.45))
            cv2.ellipse(mask, (center_x, center_y), face_axes, 0, 0, 360, 1, -1)
            
            # å˜´å·´åŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾11ï¼ˆé‡è¦ï¼ï¼‰
            mouth_y = center_y + int(h * 0.15)
            mouth_axes = (int(w * 0.15), int(h * 0.08))
            cv2.ellipse(mask, (center_x, mouth_y), mouth_axes, 0, 0, 360, 11, -1)
            
            # é¼»å­åŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾12
            nose_y = center_y
            nose_axes = (int(w * 0.08), int(h * 0.1))
            cv2.ellipse(mask, (center_x, nose_y), nose_axes, 0, 0, 360, 12, -1)
            
            # çœ¼ç›åŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾6
            eye_y = center_y - int(h * 0.1)
            eye_offset = int(w * 0.12)
            eye_axes = (int(w * 0.08), int(h * 0.05))
            cv2.ellipse(mask, (center_x - eye_offset, eye_y), eye_axes, 0, 0, 360, 6, -1)
            cv2.ellipse(mask, (center_x + eye_offset, eye_y), eye_axes, 0, 0, 360, 6, -1)
            
            return mask
        return None
    
    def parse(self, image):
        """å…¼å®¹parseæ–¹æ³•"""
        return self.__call__(image)

class OptimizedPreprocessor:
    """ä¼˜åŒ–çš„é¢„å¤„ç†å™¨ - ä¿®å¤é˜´å½±é—®é¢˜ï¼Œæé€Ÿå¤„ç†"""
    
    def __init__(self):
        self.vae = None
        self.unet = None
        self.pe = None
        self.fp = None
        self.device = None
        self.weight_dtype = torch.float16
        self.is_initialized = False
        
        # ğŸ¨ é˜´å½±ä¿®å¤å‚æ•°
        self.shadow_fix_enabled = True
        self.lighting_adjustment = True
        self.color_correction = True
        
    def initialize_models(self, device='cuda:0'):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if self.is_initialized:
            return True
            
        try:
            print(f"åˆå§‹åŒ–é¢„å¤„ç†æ¨¡å‹ - è®¾å¤‡: {device}")
            self.device = device
            
            # åŠ è½½æ¨¡å‹ - æ·»åŠ é”™è¯¯å¤„ç†
            try:
                vae, unet, pe = load_all_model()
                print("é¢„å¤„ç†æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"é¢„å¤„ç†æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                # å°è¯•ä½¿ç”¨å¤‡ç”¨VAEè·¯å¾„
                try:
                    vae, unet, pe = load_all_model(vae_type="sd-vae-ft-mse")
                    print("é¢„å¤„ç†ä½¿ç”¨å¤‡ç”¨VAEæ¨¡å‹åŠ è½½æˆåŠŸ")
                except Exception as e2:
                    print(f"é¢„å¤„ç†å¤‡ç”¨æ¨¡å‹ä¹ŸåŠ è½½å¤±è´¥: {e2}")
                    raise e2
            
            # ä¿®å¤æ¨¡å‹å¯¹è±¡å…¼å®¹æ€§ - ä½¿ç”¨æ­£ç¡®çš„å±æ€§ç»“æ„
            if hasattr(vae, 'vae'):
                vae.vae = vae.vae.to(device).half().eval()
                self.vae = vae
            elif hasattr(vae, 'to'):
                self.vae = vae.to(device).half().eval()
            else:
                print("è­¦å‘Š: VAEå¯¹è±¡ç»“æ„ä¸æ˜ï¼Œè·³è¿‡ä¼˜åŒ–")
                self.vae = vae
            
            if hasattr(unet, 'model'):
                unet.model = unet.model.to(device).half().eval()
                self.unet = unet
            elif hasattr(unet, 'to'):
                self.unet = unet.to(device).half().eval()
            else:
                print("è­¦å‘Š: UNetå¯¹è±¡ç»“æ„ä¸æ˜ï¼Œè·³è¿‡ä¼˜åŒ–")
                self.unet = unet
            
            if hasattr(pe, 'to'):
                self.pe = pe.to(device).half().eval()
            else:
                print("è­¦å‘Š: PEå¯¹è±¡æ²¡æœ‰.to()æ–¹æ³•ï¼Œè·³è¿‡ä¼˜åŒ–")
                self.pe = pe
            
            # åˆå§‹åŒ–é¢éƒ¨è§£æ - ä¼˜å…ˆä½¿ç”¨çœŸæ­£çš„FaceParsing
            if FACE_PARSING_AVAILABLE:
                try:
                    self.fp = FaceParsing()
                    print("ä½¿ç”¨MuseTalkåŸç”ŸFaceParsing")
                except Exception as e:
                    print(f"FaceParsingåˆå§‹åŒ–å¤±è´¥: {e}")
                    self.fp = SimpleFaceParsing()
                    print("é™çº§åˆ°SimpleFaceParsing")
            else:
                self.fp = SimpleFaceParsing()
                print("ä½¿ç”¨SimpleFaceParsingæ›¿ä»£å®ç°")
            
            print("é¢„å¤„ç†æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            self.is_initialized = True
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def fix_face_shadows(self, image):
        """ä¿®å¤é¢éƒ¨é˜´å½±é—®é¢˜"""
        if not self.shadow_fix_enabled:
            return image
        
        try:
            # ğŸ¨ 1. å…‰ç…§å‡è¡¡åŒ–
            if self.lighting_adjustment:
                # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´è¿›è¡Œå…‰ç…§è°ƒæ•´
                lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
                l_channel = lab[:, :, 0]
                
                # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                l_channel = clahe.apply(l_channel)
                
                lab[:, :, 0] = l_channel
                image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            
            # ğŸ¨ 2. é˜´å½±æ£€æµ‹å’Œä¿®å¤
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ£€æµ‹é˜´å½±åŒºåŸŸ
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
            dilated = cv2.dilate(gray, kernel)
            shadow_mask = cv2.absdiff(dilated, gray)
            
            # é˜ˆå€¼å¤„ç†å¾—åˆ°é˜´å½±åŒºåŸŸ
            _, shadow_mask = cv2.threshold(shadow_mask, 30, 255, cv2.THRESH_BINARY)
            
            # å¯¹é˜´å½±åŒºåŸŸè¿›è¡Œäº®åº¦æå‡
            shadow_areas = shadow_mask > 0
            if np.any(shadow_areas):
                # æå‡é˜´å½±åŒºåŸŸäº®åº¦
                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                hsv[:, :, 2][shadow_areas] = np.clip(
                    hsv[:, :, 2][shadow_areas] * 1.3, 0, 255
                ).astype(np.uint8)
                image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            
            # ğŸ¨ 3. é¢œè‰²æ ¡æ­£
            if self.color_correction:
                # ç™½å¹³è¡¡è°ƒæ•´
                image = self.white_balance_correction(image)
                
                # è‚¤è‰²å¢å¼º
                image = self.skin_tone_enhancement(image)
            
            return image
            
        except Exception as e:
            print(f"é˜´å½±ä¿®å¤å¤±è´¥: {str(e)}")
            return image
    
    def white_balance_correction(self, image):
        """ç™½å¹³è¡¡æ ¡æ­£"""
        try:
            # Gray Worldç®—æ³•
            b, g, r = cv2.split(image)
            
            b_avg = np.mean(b)
            g_avg = np.mean(g) 
            r_avg = np.mean(r)
            
            # è®¡ç®—å¢ç›Š
            k = (b_avg + g_avg + r_avg) / 3
            kb = k / b_avg
            kg = k / g_avg
            kr = k / r_avg
            
            # åº”ç”¨å¢ç›Š
            b = np.clip(b * kb, 0, 255).astype(np.uint8)
            g = np.clip(g * kg, 0, 255).astype(np.uint8)
            r = np.clip(r * kr, 0, 255).astype(np.uint8)
            
            return cv2.merge([b, g, r])
            
        except:
            return image
    
    def skin_tone_enhancement(self, image):
        """è‚¤è‰²å¢å¼º"""
        try:
            # è½¬æ¢åˆ°YUVè‰²å½©ç©ºé—´
            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
            
            # è‚¤è‰²èŒƒå›´æ£€æµ‹
            lower_skin = np.array([0, 133, 77], dtype=np.uint8)
            upper_skin = np.array([255, 173, 127], dtype=np.uint8)
            
            skin_mask = cv2.inRange(yuv, lower_skin, upper_skin)
            
            # å¯¹è‚¤è‰²åŒºåŸŸè¿›è¡Œå¾®è°ƒ
            if np.any(skin_mask > 0):
                # è½»å¾®å¢å¼ºçº¢è‰²é€šé“
                bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
                b, g, r = cv2.split(bgr)
                
                skin_areas = skin_mask > 0
                r[skin_areas] = np.clip(r[skin_areas] * 1.05, 0, 255).astype(np.uint8)
                
                return cv2.merge([b, g, r])
            
            return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
            
        except:
            return image
    
    def preprocess_template_ultra_fast(self, template_path, output_dir, template_id):
        """æé€Ÿé¢„å¤„ç†æ¨¡æ¿ - ä¿®å¤é˜´å½±é—®é¢˜ï¼Œä¼˜åŒ–æ€§èƒ½"""
        try:
            start_time = time.time()  # æ·»åŠ start_timeå®šä¹‰
            print(f"å¼€å§‹æé€Ÿé¢„å¤„ç†: {template_id}")
            
            # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
            if not self.is_initialized:
                print("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åˆå§‹åŒ–...")
                if not self.initialize_models():
                    raise RuntimeError("æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            
            # å†æ¬¡æ£€æŸ¥VAEæ˜¯å¦å­˜åœ¨
            if self.vae is None:
                print("VAEæœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½æ¨¡å‹...")
                from musetalk.utils.utils import load_all_model
                vae, unet, pe = load_all_model()
                self.vae = vae
                self.unet = unet
                self.pe = pe
                print("æ¨¡å‹é‡æ–°åŠ è½½å®Œæˆ")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            template_output_dir = os.path.join(output_dir, template_id)
            os.makedirs(template_output_dir, exist_ok=True)
            print(f"ä½¿ç”¨ç¼“å­˜ç›®å½•: {template_output_dir}")
            
            # 1. å¹¶è¡Œè¯»å–å’Œå¤„ç†å›¾åƒ
            print("è¯»å–æ¨¡æ¿å›¾åƒ...")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥çš„å›¾åƒæ–‡ä»¶è·¯å¾„
            template_path_obj = Path(template_path)
            if template_path_obj.is_file() and template_path_obj.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                input_image_path = str(template_path_obj)
                print(f"ä½¿ç”¨ç›´æ¥å›¾åƒæ–‡ä»¶: {input_image_path}")
            else:
                # åœ¨ç›®å½•ä¸­æœç´¢å›¾åƒæ–‡ä»¶
                image_files = []
                for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                    image_files.extend(template_path_obj.glob(ext))
                
                if not image_files:
                    raise ValueError(f"æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {template_path}")
                
                # é€‰æ‹©æœ€ä½³å›¾åƒï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€å¼ ï¼‰
                input_image_path = str(image_files[0])
                print(f"ä½¿ç”¨ç›®å½•ä¸­çš„å›¾åƒ: {input_image_path}")
            
            # ğŸ¨ 2. å›¾åƒé¢„å¤„ç†å’Œé˜´å½±ä¿®å¤
            print("ğŸ¨ å›¾åƒé¢„å¤„ç†å’Œé˜´å½±ä¿®å¤...")
            image = cv2.imread(input_image_path)
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {input_image_path}")
            
            # å…³é”®ï¼šé˜´å½±ä¿®å¤
            image = self.fix_face_shadows(image)
            
            # 3. é¢éƒ¨æ£€æµ‹å’Œå…³é”®ç‚¹æå–
            print("ğŸ‘¤ é¢éƒ¨æ£€æµ‹å’Œå…³é”®ç‚¹æå–...")
            # ä¿å­˜ä¸´æ—¶å›¾åƒæ–‡ä»¶ç»™get_landmark_and_bboxä½¿ç”¨
            temp_image_path = os.path.join(output_dir, "temp_image.jpg")
            cv2.imwrite(temp_image_path, image)
            
            # è°ƒè¯•ï¼šæ£€æŸ¥å›¾åƒæ˜¯å¦æ­£ç¡®ä¿å­˜
            if os.path.exists(temp_image_path):
                img_check = cv2.imread(temp_image_path)
                print(f"ä¸´æ—¶å›¾åƒ: {img_check.shape if img_check is not None else 'None'}")
            
            coord_list, frame_list = get_landmark_and_bbox([temp_image_path])
            
            # è°ƒè¯•ï¼šæ‰“å°è¿”å›å€¼
            print(f"coord_listé•¿åº¦: {len(coord_list) if coord_list else 0}")
            print(f"frame_listé•¿åº¦: {len(frame_list) if frame_list else 0}")
            if coord_list and len(coord_list) > 0:
                print(f"ç¬¬ä¸€ä¸ªcoordç±»å‹: {type(coord_list[0])}")
                if hasattr(coord_list[0], 'shape'):
                    print(f"ç¬¬ä¸€ä¸ªcoord shape: {coord_list[0].shape}")
                # æ‰“å°å®é™…çš„å€¼çœ‹çœ‹
                if isinstance(coord_list[0], np.ndarray):
                    print(f"å‰5ä¸ªå…³é”®ç‚¹: {coord_list[0][:5]}")
                    print(f"éé›¶å€¼æ•°é‡: {np.count_nonzero(coord_list[0])}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_image_path):
                os.remove(temp_image_path)
            
            if not coord_list or not frame_list:
                raise ValueError("é¢éƒ¨æ£€æµ‹å¤±è´¥")
            
            # 4. é¢éƒ¨è§£æå’Œç‰¹å¾æå–
            print("ğŸ­ é¢éƒ¨è§£æå’Œç‰¹å¾æå–...")
            mask_coords_list, mask_list = [], []
            face_parsing_masks = []  # å­˜å‚¨é¢éƒ¨è§£æçš„mask
            
            # ä½¿ç”¨coord_listä½œä¸ºbbox_listï¼ˆä»get_landmark_and_bboxè¿”å›çš„ï¼‰
            for i, (frame, landmarks) in enumerate(zip(frame_list, coord_list)):
                if landmarks is None:
                    print(f"è­¦å‘Š: ç¬¬{i}å¸§æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸")
                    continue
                    
                # coord_listè¿”å›çš„æ˜¯å…³é”®ç‚¹åæ ‡ï¼Œä¸æ˜¯è¾¹ç•Œæ¡†
                # éœ€è¦ä»å…³é”®ç‚¹è®¡ç®—è¾¹ç•Œæ¡†
                if isinstance(landmarks, np.ndarray):
                    print(f"å…³é”®ç‚¹æ•°æ®: shape={landmarks.shape}, dtype={landmarks.dtype}")
                    if landmarks.shape[0] > 0:
                        # è®¡ç®—è¾¹ç•Œæ¡† (x_min, y_min, x_max, y_max)
                        x_coords = landmarks[:, 0]
                        y_coords = landmarks[:, 1]
                        
                        # æ£€æŸ¥åæ ‡èŒƒå›´
                        print(f"Xåæ ‡èŒƒå›´: {np.min(x_coords):.2f} - {np.max(x_coords):.2f}")
                        print(f"Yåæ ‡èŒƒå›´: {np.min(y_coords):.2f} - {np.max(y_coords):.2f}")
                        
                        # å¦‚æœåæ ‡å…¨æ˜¯0ï¼Œä½¿ç”¨æ•´ä¸ªå›¾åƒä½œä¸ºäººè„¸åŒºåŸŸ
                        if np.max(x_coords) == 0 and np.max(y_coords) == 0:
                            print("è­¦å‘Š: å…³é”®ç‚¹å…¨æ˜¯0ï¼Œå°è¯•ä½¿ç”¨face_alignmenté‡æ–°æ£€æµ‹...")
                            
                            # å°è¯•ä½¿ç”¨face_alignmentç›´æ¥æ£€æµ‹
                            try:
                                from face_alignment import FaceAlignment, LandmarksType
                                fa = FaceAlignment(LandmarksType.TWO_D, flip_input=False, device='cuda')
                                preds = fa.get_landmarks(frame)
                                
                                if preds and len(preds) > 0:
                                    landmarks_new = preds[0]  # ç¬¬ä¸€ä¸ªäººè„¸
                                    x_coords = landmarks_new[:, 0]
                                    y_coords = landmarks_new[:, 1]
                                    print(f"face_alignmentæ£€æµ‹æˆåŠŸ: XèŒƒå›´ {np.min(x_coords):.0f}-{np.max(x_coords):.0f}, YèŒƒå›´ {np.min(y_coords):.0f}-{np.max(y_coords):.0f}")
                                    
                                    x_min = int(np.min(x_coords))
                                    y_min = int(np.min(y_coords))
                                    x_max = int(np.max(x_coords))
                                    y_max = int(np.max(y_coords))
                                    
                                    # æ·»åŠ è¾¹è·
                                    margin = 50
                                    x_min = max(0, x_min - margin)
                                    y_min = max(0, y_min - margin)
                                    x_max = min(frame.shape[1], x_max + margin)
                                    y_max = min(frame.shape[0], y_max + margin)
                                    
                                    face_box = [x_min, y_min, x_max, y_max]
                                    print(f"é‡æ–°æ£€æµ‹çš„è¾¹ç•Œæ¡†: {face_box}")
                                else:
                                    raise Exception("face_alignmentæœªæ£€æµ‹åˆ°äººè„¸")
                                    
                            except Exception as fa_error:
                                print(f"face_alignmentæ£€æµ‹å¤±è´¥: {fa_error}")
                                # ä½¿ç”¨é»˜è®¤å€¼
                                h, w = frame.shape[:2]
                                margin = min(w, h) // 8
                                x_min = margin
                                y_min = margin
                                x_max = w - margin
                                y_max = h - margin
                                face_box = [x_min, y_min, x_max, y_max]
                                print(f"ä½¿ç”¨é»˜è®¤è¾¹ç•Œæ¡†: {face_box}")
                        # å¦‚æœåæ ‡æ˜¯å½’ä¸€åŒ–çš„ï¼ˆ0-1èŒƒå›´ï¼‰ï¼Œéœ€è¦ç¼©æ”¾åˆ°å›¾åƒå°ºå¯¸
                        elif np.max(x_coords) <= 1.0 and np.max(y_coords) <= 1.0:
                            h, w = frame.shape[:2]
                            x_coords = x_coords * w
                            y_coords = y_coords * h
                            print(f"æ£€æµ‹åˆ°å½’ä¸€åŒ–åæ ‡ï¼Œç¼©æ”¾åˆ°å›¾åƒå°ºå¯¸: {w}x{h}")
                            
                            x_min = int(np.min(x_coords))
                            y_min = int(np.min(y_coords))
                            x_max = int(np.max(x_coords))
                            y_max = int(np.max(y_coords))
                            
                            # æ·»åŠ ä¸€äº›è¾¹è·
                            margin = 30
                            x_min = max(0, x_min - margin)
                            y_min = max(0, y_min - margin)
                            x_max = min(frame.shape[1], x_max + margin)
                            y_max = min(frame.shape[0], y_max + margin)
                            
                            face_box = [x_min, y_min, x_max, y_max]
                        else:
                            # æ­£å¸¸åæ ‡
                            x_min = int(np.min(x_coords))
                            y_min = int(np.min(y_coords))
                            x_max = int(np.max(x_coords))
                            y_max = int(np.max(y_coords))
                            
                            # æ·»åŠ ä¸€äº›è¾¹è·
                            margin = 30
                            x_min = max(0, x_min - margin)
                            y_min = max(0, y_min - margin)
                            x_max = min(frame.shape[1], x_max + margin)
                            y_max = min(frame.shape[0], y_max + margin)
                            
                            face_box = [x_min, y_min, x_max, y_max]
                        
                        print(f"è®¡ç®—çš„è¾¹ç•Œæ¡†: {face_box}")
                    else:
                        print(f"è­¦å‘Š: å…³é”®ç‚¹ä¸ºç©º")
                        continue
                else:
                    print(f"è­¦å‘Š: å…³é”®ç‚¹ç±»å‹ä¸æ­£ç¡®: {type(landmarks)}")
                    continue
                
                # é¢éƒ¨è§£æ - ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•è°ƒç”¨
                try:
                    # å°è¯•å¸¸è§çš„é¢éƒ¨è§£ææ–¹æ³•
                    if self.fp is not None and hasattr(self.fp, '__call__'):
                        try:
                            result = self.fp(frame)
                            # æ£€æŸ¥è¿”å›å€¼ç±»å‹å¹¶æ­£ç¡®å¤„ç†
                            if result is None:
                                print("é¢éƒ¨è§£æè¿”å›Noneï¼Œä½¿ç”¨é»˜è®¤mask")
                                mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                            elif isinstance(result, tuple) and len(result) > 0:
                                mask_out = result[0] if isinstance(result[0], np.ndarray) else np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                            elif isinstance(result, np.ndarray):
                                mask_out = result
                            elif isinstance(result, (int, float)):
                                # å¦‚æœè¿”å›æ•°å­—ï¼Œåˆ›å»ºé»˜è®¤mask
                                print(f"é¢éƒ¨è§£æè¿”å›æ•°å­—: {result}")
                                mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                            else:
                                print(f"é¢éƒ¨è§£æè¿”å›æœªçŸ¥ç±»å‹: {type(result)}")
                                mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                        except (TypeError, ValueError) as te:
                            print(f"é¢éƒ¨è§£æè°ƒç”¨é”™è¯¯ï¼ˆå·²å¤„ç†ï¼‰: {te}")
                            mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                    elif self.fp is not None and hasattr(self.fp, 'parse'):
                        mask_out = self.fp.parse(frame)
                    elif self.fp is not None and hasattr(self.fp, 'predict'):
                        mask_out = self.fp.predict(frame)
                    else:
                        print("é¢éƒ¨è§£æå¤±è´¥: FaceParsingå¯¹è±¡æ²¡æœ‰å¯ç”¨çš„è§£ææ–¹æ³•")
                        # ä½¿ç”¨é»˜è®¤maskï¼ˆå…¨ç™½ï¼Œè¡¨ç¤ºæ•´ä¸ªé¢éƒ¨åŒºåŸŸï¼‰
                        mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                except Exception as e:
                    print(f"é¢éƒ¨è§£æå‡ºé”™: {e}")
                    # ä½¿ç”¨é»˜è®¤mask
                    mask_out = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255
                
                # ä¿å­˜é¢éƒ¨è§£æçš„mask
                face_parsing_masks.append(mask_out)
                
                # è·å–é¢éƒ¨åŒºåŸŸåæ ‡ - ä¼ å…¥æ­£ç¡®çš„å‚æ•°
                mask, crop_box = get_image_prepare_material(frame, face_box, fp=self.fp)
                mask_coords_list.append(crop_box)
                mask_list.append(mask)
            
            # 5. VAEç¼–ç  - å¹¶è¡Œå¤„ç†
            print("VAEç¼–ç ...")
            input_latent_list = []
            
            def encode_frame(frame, mask=None):
                with torch.no_grad():
                    frame_tensor = torch.from_numpy(frame).float().to(self.device) / 127.5 - 1.0
                    frame_tensor = frame_tensor.permute(2, 0, 1).unsqueeze(0)
                    
                    # ç¼–ç åŸå§‹å¸§å¾—åˆ°reference latent (4é€šé“)
                    # VAEå¯èƒ½æœ‰ä¸åŒçš„ç¼–ç æ–¹æ³•å
                    if hasattr(self.vae, 'encode_latents'):
                        reference_latent = self.vae.encode_latents(frame_tensor)
                    elif hasattr(self.vae, 'encode'):
                        # æ ‡å‡†çš„VAE encodeæ–¹æ³•
                        latent_dist = self.vae.encode(frame_tensor)
                        if hasattr(latent_dist, 'latent_dist'):
                            reference_latent = latent_dist.latent_dist.sample() * 0.18215
                        elif hasattr(latent_dist, 'sample'):
                            reference_latent = latent_dist.sample() * 0.18215
                        else:
                            reference_latent = latent_dist * 0.18215
                    else:
                        raise AttributeError(f"VAEå¯¹è±¡æ²¡æœ‰encodeæ–¹æ³•: {dir(self.vae)}")
                    
                    # å¦‚æœæœ‰maskï¼Œåˆ›å»ºmaskedç‰ˆæœ¬
                    if mask is not None and mask.size > 0:
                        # è°ƒè¯•ï¼šæ‰“å°maskä¿¡æ¯
                        print(f"Face parsing mask shape: {mask.shape}, dtype: {mask.dtype}, unique values: {np.unique(mask)[:5]}")
                        
                        # å¤„ç†é¢éƒ¨è§£æmask
                        # é¢éƒ¨è§£æmaské€šå¸¸åŒ…å«ä¸åŒçš„æ ‡ç­¾å€¼ï¼ˆ0=èƒŒæ™¯ï¼Œ1-19=ä¸åŒé¢éƒ¨åŒºåŸŸï¼‰
                        # åˆ›å»ºäºŒå€¼maskï¼šéèƒŒæ™¯åŒºåŸŸä¸º1ï¼ŒèƒŒæ™¯ä¸º0
                        binary_mask = (mask > 0).astype(np.float32)
                        
                        # å¦‚æœéœ€è¦ï¼Œå¯ä»¥å¯¹maskè¿›è¡Œå¹³æ»‘å¤„ç†
                        from scipy.ndimage import gaussian_filter
                        binary_mask = gaussian_filter(binary_mask, sigma=1.0)
                        
                        # å°†maskè½¬æ¢ä¸ºtensor
                        mask_tensor = torch.from_numpy(binary_mask).float().to(self.device)
                        
                        # è°ƒæ•´maskç»´åº¦ä»¥åŒ¹é…frame_tensor
                        if len(mask_tensor.shape) == 2:  # [H, W]
                            mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
                        
                        # å¦‚æœmaskå’Œframeå°ºå¯¸ä¸åŒ¹é…ï¼Œè¿›è¡Œresize
                        if mask_tensor.shape[-2:] != frame_tensor.shape[-2:]:
                            mask_tensor = torch.nn.functional.interpolate(
                                mask_tensor, 
                                size=frame_tensor.shape[-2:], 
                                mode='bilinear', 
                                align_corners=False
                            )
                        
                        # æ‰©å±•maskåˆ°3é€šé“
                        mask_tensor = mask_tensor.repeat(1, 3, 1, 1)  # [1, 3, H, W]
                        
                        # åˆ›å»ºmasked frameï¼ˆä¿ç•™é¢éƒ¨åŒºåŸŸï¼ŒèƒŒæ™¯å˜é»‘ï¼‰
                        masked_frame_tensor = frame_tensor * mask_tensor
                        masked_latent = self.vae.encode_latents(masked_frame_tensor)
                        
                        # æ‹¼æ¥maskedå’Œreference latentå¾—åˆ°8é€šé“
                        combined_latent = torch.cat([masked_latent, reference_latent], dim=1)
                    else:
                        # å¦‚æœæ²¡æœ‰maskï¼Œç›´æ¥å¤åˆ¶reference latent
                        print("No face parsing mask available, using duplicated reference latent")
                        combined_latent = torch.cat([reference_latent, reference_latent], dim=1)
                    
                    return combined_latent.cpu()
            
            # å¹¶è¡Œç¼–ç å¤šå¸§
            with ThreadPoolExecutor(max_workers=4) as executor:
                # å°†frameå’Œå¯¹åº”çš„face parsing maskä¸€èµ·ä¼ é€’
                futures = []
                for i, frame in enumerate(frame_list):
                    face_mask = face_parsing_masks[i] if i < len(face_parsing_masks) else None
                    futures.append(executor.submit(encode_frame, frame, face_mask))
                
                for future in as_completed(futures):
                    latent = future.result()
                    input_latent_list.append(latent)
            
            # 6. åˆ›å»ºå¾ªç¯æ•°æ®
            print("ğŸ”„ åˆ›å»ºå¾ªç¯æ•°æ®...")
            
            # éªŒè¯latenté€šé“æ•°
            if input_latent_list:
                latent_shape = input_latent_list[0].shape
                print(f"âœ… Latentå½¢çŠ¶: {latent_shape} (åº”è¯¥æ˜¯8é€šé“)")
                if latent_shape[1] != 8:
                    print(f"âš ï¸ è­¦å‘Š: Latenté€šé“æ•°ä¸º{latent_shape[1]}ï¼ŒæœŸæœ›ä¸º8é€šé“")
            
            # å¦‚æœåªæœ‰ä¸€å¸§ï¼Œå¤åˆ¶åˆ›å»ºå¾ªç¯
            if len(input_latent_list) == 1:
                input_latent_list_cycle = input_latent_list * 2
                coord_list_cycle = coord_list * 2
                frame_list_cycle = frame_list * 2
                mask_coords_list_cycle = mask_coords_list * 2
                mask_list_cycle = mask_list * 2
            else:
                input_latent_list_cycle = input_latent_list
                coord_list_cycle = coord_list
                frame_list_cycle = frame_list
                mask_coords_list_cycle = mask_coords_list
                mask_list_cycle = mask_list
            
            # 7. ä¿å­˜é¢„å¤„ç†ç¼“å­˜
            print("ğŸ’¾ ä¿å­˜é¢„å¤„ç†ç¼“å­˜...")
            
            cache_data = {
                'input_latent_list_cycle': input_latent_list_cycle,
                'coord_list_cycle': coord_list_cycle,
                'frame_list_cycle': frame_list_cycle,
                'mask_coords_list_cycle': mask_coords_list_cycle,
                'mask_list_cycle': mask_list_cycle,
            }
            
            # ä¿å­˜ç¼“å­˜æ–‡ä»¶åˆ°æ¨¡æ¿å­ç›®å½•
            cache_file = os.path.join(template_output_dir, f"{template_id}_preprocessed.pkl")
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                'template_id': template_id,
                'template_path': template_path,
                'processed_at': time.time(),
                'frame_count': len(frame_list_cycle),
                'shadow_fix_enabled': self.shadow_fix_enabled,
                'lighting_adjustment': self.lighting_adjustment,
                'color_correction': self.color_correction
            }
            
            metadata_file = os.path.join(template_output_dir, f"{template_id}_metadata.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç®€åŒ–çš„çŠ¶æ€æ–‡ä»¶ï¼ˆå…¼å®¹æ€§ï¼‰
            state_file = os.path.join(template_output_dir, "model_state.pkl")
            with open(state_file, 'wb') as f:
                pickle.dump({'status': 'completed', 'template_id': template_id}, f)
            
            total_time = time.time() - start_time
            print(f"æé€Ÿé¢„å¤„ç†å®Œæˆï¼")
            print(f"å¤„ç†ç»Ÿè®¡:")
            print(f"   - æ¨¡æ¿ID: {template_id}")
            print(f"   - å¸§æ•°: {len(frame_list_cycle)}")
            print(f"   - è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   - é˜´å½±ä¿®å¤: {'å¯ç”¨' if self.shadow_fix_enabled else 'ç¦ç”¨'}")
            print(f"   - ç¼“å­˜æ–‡ä»¶: {cache_file}")
            
            return True
            
        except Exception as e:
            print(f"é¢„å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

def main():
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆæ¨¡æ¿é¢„å¤„ç†')
    parser.add_argument('--template_path', type=str, required=True, help='æ¨¡æ¿å›¾åƒè·¯å¾„')
    parser.add_argument('--output_dir', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--template_id', type=str, required=True, help='æ¨¡æ¿ID')
    parser.add_argument('--device', type=str, default='cuda:0', help='è®¾å¤‡')
    parser.add_argument('--disable_shadow_fix', action='store_true', help='ç¦ç”¨é˜´å½±ä¿®å¤')
    parser.add_argument('--disable_lighting', action='store_true', help='ç¦ç”¨å…‰ç…§è°ƒæ•´')
    parser.add_argument('--disable_color_correction', action='store_true', help='ç¦ç”¨é¢œè‰²æ ¡æ­£')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = OptimizedPreprocessor()
    
    # é…ç½®é˜´å½±ä¿®å¤é€‰é¡¹
    preprocessor.shadow_fix_enabled = not args.disable_shadow_fix
    preprocessor.lighting_adjustment = not args.disable_lighting
    preprocessor.color_correction = not args.disable_color_correction
    
    print(f"ğŸ¨ é˜´å½±ä¿®å¤é…ç½®:")
    print(f"   - é˜´å½±ä¿®å¤: {'å¯ç”¨' if preprocessor.shadow_fix_enabled else 'ç¦ç”¨'}")
    print(f"   - å…‰ç…§è°ƒæ•´: {'å¯ç”¨' if preprocessor.lighting_adjustment else 'ç¦ç”¨'}")
    print(f"   - é¢œè‰²æ ¡æ­£: {'å¯ç”¨' if preprocessor.color_correction else 'ç¦ç”¨'}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    if not preprocessor.initialize_models(args.device):
        print("æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        return
    
    # æ‰§è¡Œé¢„å¤„ç†
    success = preprocessor.preprocess_template_ultra_fast(
        args.template_path,
        args.output_dir, 
        args.template_id
    )
    
    if success:
        print("é¢„å¤„ç†æˆåŠŸå®Œæˆ")
    else:
        print("é¢„å¤„ç†å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()