#!/usr/bin/env python3
"""
Enhanced MuseTalk Preprocessing System
åŸºäºMuseTalkå®˜æ–¹å®æ—¶æ¨ç†æœºåˆ¶çš„ä¼˜åŒ–é¢„å¤„ç†ç³»ç»Ÿ

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. é¢éƒ¨ç‰¹å¾é¢„æå–ï¼ˆVAEç¼–ç ã€åæ ‡ã€æ©ç ç­‰ï¼‰
2. æŒä¹…åŒ–ç¼“å­˜æœºåˆ¶
3. çœŸæ­£çš„å®æ—¶æ¨ç†æ”¯æŒ

ä½œè€…: Claude Sonnet
ç‰ˆæœ¬: 1.0
"""

import os
import cv2
import torch
import numpy as np
import pickle
import json
import glob
from tqdm import tqdm
import time
from pathlib import Path

# MuseTalkç»„ä»¶å¯¼å…¥
from musetalk.utils.face_parsing import FaceParsing
from musetalk.utils.preprocessing import get_landmark_and_bbox, read_imgs
from musetalk.utils.blending import get_image_prepare_material, get_image_blending
from musetalk.utils.utils import load_all_model


class EnhancedMuseTalkPreprocessor:
    """
    å¢å¼ºçš„MuseTalké¢„å¤„ç†å™¨
    
    å®ç°çœŸæ­£çš„é¢éƒ¨ç‰¹å¾é¢„æå–ï¼ŒåŒ…æ‹¬ï¼š
    - VAEæ½œåœ¨ç¼–ç é¢„è®¡ç®—
    - é¢éƒ¨åæ ‡å’Œæ©ç é¢„æå–  
    - æŒä¹…åŒ–ç¼“å­˜æœºåˆ¶
    - å®æ—¶æ¨ç†ä¼˜åŒ–
    """
    
    def __init__(self, 
                 model_config_path="models/musetalk/musetalk.json",
                 model_weights_path="models/musetalk/pytorch_model.bin",
                 vae_type="sd-vae",
                 device="cuda:0",
                 cache_dir="./template_cache"):
        """
        åˆå§‹åŒ–å¢å¼ºé¢„å¤„ç†å™¨
        
        Args:
            model_config_path: UNetæ¨¡å‹é…ç½®è·¯å¾„
            model_weights_path: UNetæ¨¡å‹æƒé‡è·¯å¾„  
            vae_type: VAEç±»å‹
            device: è®¡ç®—è®¾å¤‡
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.device = torch.device(device)
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸš€ åˆå§‹åŒ–å¢å¼ºMuseTalké¢„å¤„ç†å™¨...")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_dir}")
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶
        self._load_models(model_weights_path, vae_type, model_config_path)
        
        # åˆå§‹åŒ–é¢éƒ¨è§£æå™¨
        self.face_parser = FaceParsing()
        
        print(f"âœ… é¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_models(self, model_weights_path, vae_type, model_config_path):
        """åŠ è½½æ¨¡å‹ç»„ä»¶"""
        print(f"ğŸ”§ åŠ è½½æ¨¡å‹ç»„ä»¶...")
        
        # åŠ è½½VAE, UNet, PEç­‰ç»„ä»¶
        self.vae, self.unet, self.pe = load_all_model(
            unet_model_path=model_weights_path,
            vae_type=vae_type,
            unet_config=model_config_path,
            device=self.device
        )
        
        print(f"âœ… æ¨¡å‹ç»„ä»¶åŠ è½½å®Œæˆ")
    
    def preprocess_template(self, 
                          template_id, 
                          template_image_path, 
                          bbox_shift=0,
                          parsing_mode="jaw",
                          force_refresh=False):
        """
        é¢„å¤„ç†æ¨¡æ¿ï¼Œæå–å¹¶ç¼“å­˜æ‰€æœ‰é¢éƒ¨ç‰¹å¾
        
        Args:
            template_id: æ¨¡æ¿å”¯ä¸€ID
            template_image_path: æ¨¡æ¿å›¾ç‰‡è·¯å¾„
            bbox_shift: è¾¹ç•Œæ¡†åç§»
            parsing_mode: é¢éƒ¨è§£ææ¨¡å¼  
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
            
        Returns:
            dict: é¢„å¤„ç†ç»“æœä¿¡æ¯
        """
        cache_path = self.cache_dir / f"{template_id}_preprocessed.pkl"
        metadata_path = self.cache_dir / f"{template_id}_metadata.json"
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and cache_path.exists() and metadata_path.exists():
            print(f"ğŸ“¦ å‘ç°ç¼“å­˜: {template_id}")
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # éªŒè¯ç¼“å­˜å®Œæ•´æ€§
            if self._validate_cache(cache_path, metadata):
                print(f"âœ… ç¼“å­˜æœ‰æ•ˆï¼Œè·³è¿‡é¢„å¤„ç†: {template_id}")
                return metadata
            else:
                print(f"âš ï¸ ç¼“å­˜æ— æ•ˆï¼Œé‡æ–°é¢„å¤„ç†: {template_id}")
        
        print(f"ğŸ¯ å¼€å§‹é¢„å¤„ç†æ¨¡æ¿: {template_id}")
        start_time = time.time()
        
        # è¯»å–æ¨¡æ¿å›¾ç‰‡
        if not os.path.exists(template_image_path):
            raise FileNotFoundError(f"æ¨¡æ¿å›¾ç‰‡ä¸å­˜åœ¨: {template_image_path}")
        
        template_img = cv2.imread(template_image_path)
        if template_img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {template_image_path}")
        
        print(f"ğŸ“¸ æ¨¡æ¿å›¾ç‰‡: {template_image_path}, å°ºå¯¸: {template_img.shape}")
        
        # 1. é¢éƒ¨æ£€æµ‹å’Œåæ ‡æå–
        print(f"ğŸ” æå–é¢éƒ¨åæ ‡...")
        coord_list, frame_list = get_landmark_and_bbox([template_image_path], bbox_shift)
        
        if not coord_list or coord_list[0] == (0.0, 0.0, 0.0, 0.0):
            raise ValueError(f"æœªæ£€æµ‹åˆ°æœ‰æ•ˆé¢éƒ¨: {template_image_path}")
        
        bbox = coord_list[0]
        frame = frame_list[0]
        x1, y1, x2, y2 = bbox
        
        print(f"ğŸ“ é¢éƒ¨åæ ‡: ({x1}, {y1}, {x2}, {y2})")
        
        # 2. VAEæ½œåœ¨ç¼–ç é¢„è®¡ç®—
        print(f"ğŸ§  è®¡ç®—VAEæ½œåœ¨ç¼–ç ...")
        crop_frame = frame[y1:y2, x1:x2]
        resized_crop_frame = cv2.resize(crop_frame, (256, 256), interpolation=cv2.INTER_LANCZOS4)
        
        with torch.no_grad():
            input_latent = self.vae.get_latents_for_unet(resized_crop_frame)
        
        print(f"ğŸ’¾ VAEç¼–ç å°ºå¯¸: {input_latent.shape}")
        
        # 3. é¢éƒ¨æ©ç å’ŒèåˆåŒºåŸŸé¢„è®¡ç®—
        print(f"ğŸ­ è®¡ç®—é¢éƒ¨æ©ç ...")
        mask, mask_crop_box = get_image_prepare_material(
            frame, [x1, y1, x2, y2], 
            fp=self.face_parser, 
            mode=parsing_mode
        )
        
        print(f"ğŸ­ æ©ç å°ºå¯¸: {mask.shape}, èåˆåŒºåŸŸ: {mask_crop_box}")
        
        # 4. åˆ›å»ºå¾ªç¯æ•°æ®ï¼ˆæ­£å‘+åå‘ï¼Œç¬¦åˆMuseTalkå®˜æ–¹å®ç°ï¼‰
        frame_list_cycle = [frame] + [frame][::-1] if len([frame]) > 1 else [frame] * 2
        coord_list_cycle = [bbox] + [bbox][::-1] if len([bbox]) > 1 else [bbox] * 2
        input_latent_list_cycle = [input_latent] + [input_latent][::-1] if len([input_latent]) > 1 else [input_latent] * 2
        mask_list_cycle = [mask] + [mask][::-1] if len([mask]) > 1 else [mask] * 2
        mask_coords_list_cycle = [mask_crop_box] + [mask_crop_box][::-1] if len([mask_crop_box]) > 1 else [mask_crop_box] * 2
        
        # 5. å‡†å¤‡ç¼“å­˜æ•°æ®
        preprocessed_data = {
            'frame_list_cycle': frame_list_cycle,
            'coord_list_cycle': coord_list_cycle,
            'input_latent_list_cycle': input_latent_list_cycle,
            'mask_list_cycle': mask_list_cycle,
            'mask_coords_list_cycle': mask_coords_list_cycle,
            'original_bbox': bbox,
            'processed_at': time.time()
        }
        
        # 6. ä¿å­˜ç¼“å­˜
        print(f"ğŸ’¾ ä¿å­˜é¢„å¤„ç†ç¼“å­˜...")
        with open(cache_path, 'wb') as f:
            pickle.dump(preprocessed_data, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        # 7. ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'template_id': template_id,
            'template_image_path': template_image_path,
            'bbox_shift': bbox_shift,
            'parsing_mode': parsing_mode,
            'bbox': bbox,
            'processing_time': time.time() - start_time,
            'processed_at': time.time(),
            'cache_path': str(cache_path),
            'frame_count': len(frame_list_cycle),
            'input_latent_shape': list(input_latent.shape),
            'version': '1.0'
        }
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        processing_time = time.time() - start_time
        print(f"âœ… æ¨¡æ¿é¢„å¤„ç†å®Œæˆ: {template_id}")
        print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")
        print(f"ğŸ“¦ ç¼“å­˜å¤§å°: {cache_path.stat().st_size / 1024 / 1024:.2f}MB")
        
        return metadata
    
    def _validate_cache(self, cache_path, metadata):
        """éªŒè¯ç¼“å­˜å®Œæ•´æ€§"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶å­˜åœ¨ä¸”éç©º
            if not cache_path.exists() or cache_path.stat().st_size == 0:
                return False
            
            # å°è¯•åŠ è½½ç¼“å­˜æ•°æ®
            with open(cache_path, 'rb') as f:
                data = pickle.load(f)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = [
                'frame_list_cycle', 'coord_list_cycle', 'input_latent_list_cycle',
                'mask_list_cycle', 'mask_coords_list_cycle'
            ]
            
            for field in required_fields:
                if field not in data:
                    return False
                if not data[field]:  # æ£€æŸ¥éç©º
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ ç¼“å­˜éªŒè¯å¤±è´¥: {e}")
            return False
    
    def load_preprocessed_template(self, template_id):
        """
        åŠ è½½é¢„å¤„ç†çš„æ¨¡æ¿æ•°æ®
        
        Args:
            template_id: æ¨¡æ¿ID
            
        Returns:
            dict: é¢„å¤„ç†æ•°æ®
        """
        cache_path = self.cache_dir / f"{template_id}_preprocessed.pkl"
        metadata_path = self.cache_dir / f"{template_id}_metadata.json"
        
        if not cache_path.exists():
            raise FileNotFoundError(f"æ¨¡æ¿ç¼“å­˜ä¸å­˜åœ¨: {template_id}")
        
        if not metadata_path.exists():
            raise FileNotFoundError(f"æ¨¡æ¿å…ƒæ•°æ®ä¸å­˜åœ¨: {template_id}")
        
        # åŠ è½½å…ƒæ•°æ®
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # åŠ è½½é¢„å¤„ç†æ•°æ®
        with open(cache_path, 'rb') as f:
            preprocessed_data = pickle.load(f)
        
        print(f"ğŸ“¦ åŠ è½½é¢„å¤„ç†æ¨¡æ¿: {template_id}")
        print(f"ğŸ“Š å¸§æ•°: {len(preprocessed_data['frame_list_cycle'])}")
        print(f"â±ï¸ é¢„å¤„ç†æ—¶é—´: {metadata['processed_at']}")
        
        return preprocessed_data, metadata
    
    def list_cached_templates(self):
        """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜çš„æ¨¡æ¿"""
        templates = []
        for metadata_file in self.cache_dir.glob("*_metadata.json"):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                templates.append(metadata)
            except Exception as e:
                print(f"âš ï¸ è¯»å–å…ƒæ•°æ®å¤±è´¥ {metadata_file}: {e}")
        
        return templates
    
    def clean_cache(self, template_id=None):
        """æ¸…ç†ç¼“å­˜"""
        if template_id:
            # æ¸…ç†æŒ‡å®šæ¨¡æ¿
            cache_path = self.cache_dir / f"{template_id}_preprocessed.pkl"
            metadata_path = self.cache_dir / f"{template_id}_metadata.json"
            
            for path in [cache_path, metadata_path]:
                if path.exists():
                    path.unlink()
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤: {path}")
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            for file_path in self.cache_dir.glob("*"):
                file_path.unlink()
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤: {file_path}")
    
    def get_cache_info(self):
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        templates = self.list_cached_templates()
        total_size = sum(f.stat().st_size for f in self.cache_dir.glob("*"))
        
        return {
            'cache_dir': str(self.cache_dir),
            'template_count': len(templates),
            'total_size_mb': total_size / 1024 / 1024,
            'templates': templates
        }


def main():
    """ç¤ºä¾‹ä½¿ç”¨"""
    # åˆå§‹åŒ–é¢„å¤„ç†å™¨
    preprocessor = EnhancedMuseTalkPreprocessor(
        device="cuda:0",
        cache_dir="./template_cache"
    )
    
    # ç¤ºä¾‹ï¼šé¢„å¤„ç†æ¨¡æ¿
    template_id = "xiaoha"
    template_image = "./wwwroot/templates/xiaoha.jpg"
    
    try:
        # é¢„å¤„ç†æ¨¡æ¿
        metadata = preprocessor.preprocess_template(
            template_id=template_id,
            template_image_path=template_image,
            bbox_shift=0,
            parsing_mode="jaw",
            force_refresh=False  # ä½¿ç”¨ç¼“å­˜
        )
        
        print(f"âœ… é¢„å¤„ç†å®Œæˆ: {metadata}")
        
        # åŠ è½½é¢„å¤„ç†æ•°æ®
        data, meta = preprocessor.load_preprocessed_template(template_id)
        print(f"ğŸ“¦ åŠ è½½æ•°æ®æˆåŠŸï¼Œå¸§æ•°: {len(data['frame_list_cycle'])}")
        
        # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
        cache_info = preprocessor.get_cache_info()
        print(f"ğŸ’¾ ç¼“å­˜ä¿¡æ¯: {cache_info}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")


if __name__ == "__main__":
    main()