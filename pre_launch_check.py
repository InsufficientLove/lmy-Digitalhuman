#!/usr/bin/env python3
"""
MuseTalkå¯åŠ¨å‰ç¯å¢ƒæ£€æŸ¥è„šæœ¬
"""

import os
import sys
import subprocess
import torch
import time
import threading
from pathlib import Path

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    print("ğŸ” GPUæ£€æŸ¥...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    gpu_count = torch.cuda.device_count()
    print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    # æ£€æŸ¥GPU 0çŠ¶æ€
    try:
        torch.cuda.set_device(0)
        # ç®€å•çš„GPUæµ‹è¯•
        x = torch.randn(100, 100, device='cuda:0')
        y = torch.mm(x, x)
        del x, y
        torch.cuda.empty_cache()
        print("âœ… GPU 0 æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ GPU 0 æµ‹è¯•å¤±è´¥: {e}")
        return False

def check_model_files():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("\nğŸ“ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥...")
    
    required_files = [
        'models/musetalk/musetalk.json',
        'models/musetalk/pytorch_model.bin',
        'models/sd-vae/config.json',
        'models/sd-vae/diffusion_pytorch_model.bin',
        'configs/inference/test.yaml'
    ]
    
    for file_path in required_files:
        if os.path.exists(file_path):
            size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            print(f"âœ… {file_path} ({size:.1f}MB)")
        else:
            print(f"âŒ {file_path} ç¼ºå¤±")
            return False
    
    return True

def quick_import_test():
    """å¿«é€Ÿå¯¼å…¥æµ‹è¯•"""
    print("\nğŸ§ª å¿«é€Ÿå¯¼å…¥æµ‹è¯•...")
    
    imports = [
        ("torch", "import torch"),
        ("scripts", "import scripts"),
        ("musetalk", "import musetalk"),
        ("load_all_model", "from musetalk.utils.utils import load_all_model")
    ]
    
    for name, import_code in imports:
        try:
            exec(import_code)
            print(f"âœ… {name}")
        except Exception as e:
            print(f"âŒ {name}: {e}")
            return False
    
    return True

def timeout_wrapper(func, timeout_sec=30):
    """è¶…æ—¶åŒ…è£…å™¨"""
    result = [None]
    exception = [None]
    
    def target():
        try:
            result[0] = func()
        except Exception as e:
            exception[0] = e
    
    thread = threading.Thread(target=target)
    thread.daemon = True
    thread.start()
    thread.join(timeout_sec)
    
    if thread.is_alive():
        print(f"âš ï¸  æ“ä½œè¶…æ—¶ ({timeout_sec}ç§’)")
        return False
    
    if exception[0]:
        print(f"âŒ æ“ä½œå¤±è´¥: {exception[0]}")
        return False
    
    return result[0]

def test_minimal_inference():
    """æœ€å°åŒ–inferenceæµ‹è¯•"""
    print("\nğŸš€ æœ€å°åŒ–inferenceæµ‹è¯•...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    def run_test():
        try:
            # åªå¯¼å…¥ï¼Œä¸åŠ è½½æ¨¡å‹
            from musetalk.utils.utils import load_all_model
            print("âœ… å¯¼å…¥æˆåŠŸ")
            
            # æµ‹è¯•èƒ½å¦åˆ›å»ºCUDAå¼ é‡
            import torch
            device = torch.device('cuda:0')
            test_tensor = torch.randn(10, 10, device=device)
            result = test_tensor * 2
            del test_tensor, result
            torch.cuda.empty_cache()
            print("âœ… CUDAæ“ä½œæˆåŠŸ")
            
            return True
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    return timeout_wrapper(run_test, 15)

def diagnose_hanging_issue():
    """è¯Šæ–­å¡æ­»é—®é¢˜"""
    print("\nğŸ” å¡æ­»é—®é¢˜è¯Šæ–­...")
    
    # 1. æ£€æŸ¥å…¶ä»–Pythonè¿›ç¨‹
    try:
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq python.exe'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            python_processes = [line for line in lines if 'python.exe' in line.lower()]
            if len(python_processes) > 1:
                print(f"âš ï¸  æ£€æµ‹åˆ° {len(python_processes)} ä¸ªPythonè¿›ç¨‹:")
                for proc in python_processes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"   {proc.strip()}")
                print("ğŸ’¡ å»ºè®®ï¼šå…³é—­å…¶ä»–Pythonè¿›ç¨‹é¿å…å†²çª")
    except:
        pass
    
    # 2. æ£€æŸ¥GPUè¿›ç¨‹
    try:
        result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,process_name,gpu_uuid,used_memory', 
                               '--format=csv,noheader'], capture_output=True, text=True)
        if result.returncode == 0 and result.stdout.strip():
            print("âš ï¸  æ£€æµ‹åˆ°GPUä¸Šçš„å…¶ä»–è¿›ç¨‹:")
            print(result.stdout)
            print("ğŸ’¡ å»ºè®®ï¼šç»“æŸå…¶ä»–GPUè¿›ç¨‹")
    except:
        pass
    
    # 3. ç¯å¢ƒå˜é‡æ£€æŸ¥
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES')
    print(f"ğŸ“‹ CUDA_VISIBLE_DEVICES: {cuda_devices}")
    
    return True

def main():
    print("ğŸ› ï¸  MuseTalkå¯åŠ¨å‰ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    # ç¡®ä¿åœ¨MuseTalkç›®å½•ä¸­
    if 'MuseTalk' not in os.getcwd():
        print("âŒ è¯·åœ¨MuseTalkç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
        print(f"å½“å‰ç›®å½•: {os.getcwd()}")
        return
    
    checks = [
        ("GPUå¯ç”¨æ€§", check_gpu_availability),
        ("æ¨¡å‹æ–‡ä»¶", check_model_files),
        ("æ¨¡å—å¯¼å…¥", quick_import_test),
        ("æœ€å°åŒ–æµ‹è¯•", test_minimal_inference),
        ("é—®é¢˜è¯Šæ–­", diagnose_hanging_issue)
    ]
    
    all_passed = True
    for check_name, check_func in checks:
        print(f"\n{'='*20} {check_name} {'='*20}")
        if not check_func():
            all_passed = False
            print(f"âŒ {check_name} å¤±è´¥")
        else:
            print(f"âœ… {check_name} é€šè¿‡")
    
    print("\n" + "="*60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼MuseTalkåº”è¯¥å¯ä»¥æ­£å¸¸å¯åŠ¨")
        print("\nğŸ’¡ å¦‚æœä»ç„¶å¡æ­»ï¼Œå»ºè®®:")
        print("1. é‡å¯ç³»ç»Ÿæ¸…ç†GPUçŠ¶æ€")
        print("2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("3. å°è¯•æ›´å°çš„è¾“å…¥æ–‡ä»¶")
    else:
        print("âŒ éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜")

if __name__ == "__main__":
    main()