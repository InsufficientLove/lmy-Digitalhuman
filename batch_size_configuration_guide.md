# BatchSize 配置指南

## 配置方法

在 `appsettings.json` 中修改：

```json
"MuseTalk": {
  "BatchSize": 4,  // 根据您的GPU内存调整此值
  ...
}
```

## 推荐配置

基于您的错误信息分析：
- batch_size=6 需要 18.34GB
- batch_size=4 需要 12.23GB
- batch_size=2 虽然内存安全，但会产生过多批次（39个），导致处理缓慢
- 可用内存约 4GB（总19GB - 已用15GB）

### 推荐值：

| GPU内存状态 | 推荐BatchSize | 预计内存使用 | 说明 |
|------------|---------------|--------------|------|
| 24GB (可用15GB+) | 4-5 | 12-15GB | 最佳性能 |
| 24GB (可用10GB) | 3 | 9GB | 平衡选择 |
| 24GB (可用6GB) | 2 | 6GB | 安全但慢 |
| 24GB (可用4GB) | 1 | 3GB | 仅应急用 |

### 计算公式：
- 每个batch在推理时约需要 3.06GB
- batch_size=3: 约9.2GB（推荐）
- batch_size=4: 约12.2GB（需要清理内存）

## 性能优化建议

### 1. 清理GPU内存
在运行前执行：
```bash
# 查看GPU使用情况
nvidia-smi

# 如果有其他进程占用，考虑关闭
```

### 2. 优化批次大小
- **短音频**（<5秒）：batch_size=2-3 足够
- **长音频**（>10秒）：batch_size=4-6 更高效
- **批次数量**：理想情况下保持在10-20个批次

### 3. 内存不足的解决方案

如果持续出现内存错误：

1. **重启Python服务**
   - 清理累积的内存碎片
   - 释放被占用的GPU内存

2. **调整配置**
   ```json
   "BatchSize": 3  // 从4降到3
   ```

3. **检查其他GPU进程**
   ```cmd
   nvidia-smi
   # 查看是否有其他进程占用GPU
   ```

## 故障排除

### 常见错误

1. **CUDA out of memory**
   - 降低BatchSize
   - 重启服务释放内存

2. **'numpy.ndarray' object has no attribute 'cpu'**
   - 已在最新代码中修复
   - 确保使用最新版本

3. **批次过多导致处理缓慢**
   - 适当增加BatchSize
   - 例如：从2增加到3或4

## 监控和优化

重启后观察日志：
- `音频帧数: X`
- `4GPU并行处理 Y 批次`
- 如果Y > 20，考虑增加BatchSize

通过合理配置，您可以在内存安全和处理速度之间找到最佳平衡！