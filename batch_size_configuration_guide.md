# BatchSize 配置指南

## 配置方法

在 `appsettings.json` 中修改：

```json
"MuseTalk": {
  "BatchSize": 4,  // 根据您的GPU内存调整此值
  ...
}
```

## 推荐配置

基于您的错误信息分析：
- batch_size=6 需要 18.34GB
- batch_size=4 需要 12.23GB  
- batch_size=3 需要 9.2GB
- batch_size=2 虽然内存安全，但会产生过多批次（39个），导致处理极其缓慢

### 强烈推荐：

| 音频长度 | 推荐BatchSize | 批次数 | 性能影响 |
|---------|---------------|--------|----------|
| 短音频(<5秒) | 3-4 | 10-15 | 快速 |
| 中等音频(5-10秒) | 4-5 | 15-20 | 适中 |
| 长音频(>10秒) | 5-6 | 20-30 | 需要平衡 |

### 您的情况（78帧）：
- batch_size=2: 39批次，约80秒（太慢！）
- batch_size=4: 20批次，约40秒（推荐）
- batch_size=6: 13批次，约26秒（如果内存足够）

## 性能优化已实施

### 1. 移除了过度的内存管理
- 不再每组批次后强制清理内存
- 让CUDA自动管理内存
- 只在处理大量批次后清理一次

### 2. 真正的并行处理
- 所有批次同时提交
- 不再分组等待
- GPU保持持续忙碌

### 3. 减少同步开销
- 移除不必要的torch.cuda.synchronize()
- 使用non_blocking=True进行数据传输

## 立即行动

1. **修改配置为4**：
   ```json
   "BatchSize": 4
   ```

2. **如果仍有内存问题，尝试3**：
   ```json
   "BatchSize": 3
   ```

3. **重启Python服务以应用优化**

## 预期性能提升

- 从80秒降到20-40秒
- 真正实现4GPU并行
- 接近"毫秒级响应"的目标

## 监控建议

观察日志中的：
- "进度: X/Y 批次完成" - 应该快速更新
- 不应该看到"清理GPU内存..."频繁出现
- GPU利用率应该保持较高水平