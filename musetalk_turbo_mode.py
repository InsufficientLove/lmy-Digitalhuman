#!/usr/bin/env python3
"""
MuseTalkæ¶¡è½®å¢å‹æ¨¡å¼
å®ç°æé€Ÿæ¨ç†ï¼Œç›®æ ‡ï¼š3ç§’è§†é¢‘åœ¨10ç§’å†…å®Œæˆ
"""

import os
import sys
import time
import torch
import yaml
import argparse
from pathlib import Path

def setup_turbo_environment():
    """è®¾ç½®æ¶¡è½®å¢å‹ç¯å¢ƒå˜é‡"""
    print("ğŸš€ è®¾ç½®æ¶¡è½®å¢å‹ç¯å¢ƒ...")
    
    # æè‡´æ€§èƒ½ç¯å¢ƒå˜é‡
    turbo_env = {
        # GPUä¼˜åŒ–
        "CUDA_VISIBLE_DEVICES": "0,1,2,3",
        "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:4096,expandable_segments:True,roundup_power2_divisions:16",
        "TORCH_BACKENDS_CUDNN_BENCHMARK": "1",
        "TORCH_BACKENDS_CUDNN_DETERMINISTIC": "0",
        "TORCH_CUDNN_V8_API_ENABLED": "1",
        "TORCH_CUDNN_SDPA_ENABLED": "1",
        
        # CPUä¼˜åŒ–
        "OMP_NUM_THREADS": "32",
        "MKL_NUM_THREADS": "32",
        "NUMEXPR_NUM_THREADS": "32",
        
        # PyTorchä¼˜åŒ–
        "TORCH_COMPILE": "1",
        "TORCH_COMPILE_MODE": "max-autotune",
        "TORCH_INDUCTOR_CACHE_SIZE": "1024",
        
        # å†…å­˜ä¼˜åŒ–
        "PYTORCH_CUDA_MEMORY_FRACTION": "0.95",
        "TORCH_SHOW_CPP_STACKTRACES": "0",
        
        # å¹¶è¡Œä¼˜åŒ–
        "TOKENIZERS_PARALLELISM": "false",
        "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
        
        # è°ƒè¯•å…³é—­
        "TORCH_WARN": "0",
        "PYTHONWARNINGS": "ignore",
    }
    
    for key, value in turbo_env.items():
        os.environ[key] = value
        print(f"   {key} = {value}")

def create_turbo_config(video_path, audio_path, output_path, bbox_shift=0):
    """åˆ›å»ºæ¶¡è½®å¢å‹é…ç½®æ–‡ä»¶"""
    config = {
        "task_001": {
            "video_path": video_path.replace("\\", "/"),
            "audio_path": audio_path.replace("\\", "/"),
            "bbox_shift": bbox_shift,
            "result_name": Path(output_path).name
        }
    }
    
    config_path = f"configs/inference/turbo_{int(time.time())}.yaml"
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f)
    
    print(f"ğŸ“ åˆ›å»ºæ¶¡è½®é…ç½®: {config_path}")
    return config_path

def run_turbo_inference(video_path, audio_path, output_dir, bbox_shift=0):
    """è¿è¡Œæ¶¡è½®å¢å‹æ¨ç†"""
    print("âš¡ å¯åŠ¨æ¶¡è½®å¢å‹æ¨ç†...")
    
    # è®¾ç½®ç¯å¢ƒ
    setup_turbo_environment()
    
    # åˆ›å»ºè¾“å‡ºè·¯å¾„
    output_filename = f"turbo_output_{int(time.time())}.mp4"
    output_path = os.path.join(output_dir, output_filename)
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºé…ç½®
    config_path = create_turbo_config(video_path, audio_path, output_path, bbox_shift)
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        sys.executable, "-m", "scripts.inference",
        "--inference_config", config_path,
        "--result_dir", output_dir,
        "--gpu_id", "0",  # ä¸»GPU
        "--batch_size", "16",  # å¤§æ‰¹å¤„ç†
        "--fps", "25",
        "--use_float16",
        "--version", "v1",
        "--bbox_shift", str(bbox_shift),
        "--skip_save_images",  # è·³è¿‡ä¸­é—´å›¾ç‰‡
        "--low_latency",       # ä½å»¶è¿Ÿæ¨¡å¼
        "--optimize_memory",   # å†…å­˜ä¼˜åŒ–
    ]
    
    print(f"ğŸ¬ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        import subprocess
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)  # 2åˆ†é’Ÿè¶…æ—¶
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        if result.returncode == 0:
            print(f"âœ… æ¶¡è½®æ¨ç†æˆåŠŸ! è€—æ—¶: {processing_time:.2f}ç§’")
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘
            possible_paths = [
                output_path,
                os.path.join(output_dir, "v1", output_filename),
                os.path.join(output_dir, "v15", output_filename)
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    print(f"ğŸ“¹ æ‰¾åˆ°è¾“å‡ºè§†é¢‘: {path}")
                    file_size = os.path.getsize(path) / 1024  # KB
                    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.1f}KB")
                    return path
            
            print("âš ï¸ æ¨ç†æˆåŠŸä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
            return None
            
        else:
            print(f"âŒ æ¨ç†å¤±è´¥ (é€€å‡ºç : {result.returncode})")
            print(f"é”™è¯¯è¾“å‡º: {result.stderr}")
            return None
            
    except subprocess.TimeoutExpired:
        print("â° æ¨ç†è¶…æ—¶ (>2åˆ†é’Ÿ)")
        return None
    except Exception as e:
        print(f"ğŸ’¥ æ¨ç†å¼‚å¸¸: {e}")
        return None
    finally:
        # æ¸…ç†é…ç½®æ–‡ä»¶
        try:
            if os.path.exists(config_path):
                os.remove(config_path)
        except:
            pass

def benchmark_turbo_mode():
    """åŸºå‡†æµ‹è¯•æ¶¡è½®æ¨¡å¼"""
    print("ğŸ æ¶¡è½®æ¨¡å¼åŸºå‡†æµ‹è¯•")
    
    # æµ‹è¯•æ–‡ä»¶ï¼ˆéœ€è¦ç”¨æˆ·æä¾›ï¼‰
    test_cases = [
        {
            "name": "çŸ­éŸ³é¢‘æµ‹è¯•",
            "video": "data/test_image.jpg",
            "audio": "data/short_audio.wav",  # 1-2ç§’éŸ³é¢‘
            "target_time": 5  # ç›®æ ‡5ç§’å†…å®Œæˆ
        },
        {
            "name": "ä¸­ç­‰éŸ³é¢‘æµ‹è¯•", 
            "video": "data/test_image.jpg",
            "audio": "data/medium_audio.wav",  # 3-5ç§’éŸ³é¢‘
            "target_time": 10  # ç›®æ ‡10ç§’å†…å®Œæˆ
        }
    ]
    
    results = []
    
    for test in test_cases:
        print(f"\nğŸ§ª æ‰§è¡Œæµ‹è¯•: {test['name']}")
        
        if not (os.path.exists(test['video']) and os.path.exists(test['audio'])):
            print(f"âš ï¸ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {test['name']}")
            continue
        
        start_time = time.time()
        output_path = run_turbo_inference(
            test['video'], 
            test['audio'], 
            "benchmark_results"
        )
        end_time = time.time()
        
        processing_time = end_time - start_time
        success = output_path is not None
        meets_target = processing_time <= test['target_time']
        
        result = {
            "name": test['name'],
            "success": success,
            "time": processing_time,
            "target": test['target_time'],
            "meets_target": meets_target,
            "speedup": test['target_time'] / processing_time if processing_time > 0 else 0
        }
        
        results.append(result)
        
        status = "âœ…" if success and meets_target else "âš ï¸" if success else "âŒ"
        print(f"{status} {test['name']}: {processing_time:.2f}s (ç›®æ ‡: {test['target_time']}s)")
    
    # è¾“å‡ºæ€»ç»“
    print("\nğŸ“Š åŸºå‡†æµ‹è¯•æ€»ç»“:")
    print("=" * 60)
    for result in results:
        status = "âœ…" if result['success'] and result['meets_target'] else "âš ï¸" if result['success'] else "âŒ"
        print(f"{status} {result['name']}: {result['time']:.2f}s / {result['target']}s")
    
    return results

def main():
    parser = argparse.ArgumentParser(description="MuseTalkæ¶¡è½®å¢å‹æ¨¡å¼")
    parser.add_argument("--video", help="è¾“å…¥è§†é¢‘/å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--audio", help="è¾“å…¥éŸ³é¢‘è·¯å¾„")
    parser.add_argument("--output", default="turbo_results", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--bbox_shift", type=int, default=0, help="bbox_shiftå‚æ•°")
    parser.add_argument("--benchmark", action="store_true", help="è¿è¡ŒåŸºå‡†æµ‹è¯•")
    
    args = parser.parse_args()
    
    if args.benchmark:
        benchmark_turbo_mode()
    elif args.video and args.audio:
        result = run_turbo_inference(args.video, args.audio, args.output, args.bbox_shift)
        if result:
            print(f"ğŸ‰ æ¶¡è½®æ¨ç†å®Œæˆ: {result}")
        else:
            print("ğŸ’¥ æ¶¡è½®æ¨ç†å¤±è´¥")
    else:
        print("ğŸš€ MuseTalkæ¶¡è½®å¢å‹æ¨¡å¼")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python musetalk_turbo_mode.py --video image.jpg --audio audio.wav")
        print("  python musetalk_turbo_mode.py --benchmark")

if __name__ == "__main__":
    main()